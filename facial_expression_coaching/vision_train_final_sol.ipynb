{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29209,
     "status": "ok",
     "timestamp": 1660383858076,
     "user": {
      "displayName": "­권태희 / 학생 / 전기·정보공학부",
      "userId": "01216604526634043672"
     },
     "user_tz": -540
    },
    "id": "iAAGJxU8VqSo",
    "outputId": "db343823-d182-469b-b3e7-f00f448665fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13886,
     "status": "ok",
     "timestamp": 1660383871948,
     "user": {
      "displayName": "­권태희 / 학생 / 전기·정보공학부",
      "userId": "01216604526634043672"
     },
     "user_tz": -540
    },
    "id": "3j0M6RBg49uN",
    "outputId": "965e75f0-c4d0-4c18-dd88-bdfcde7a8a39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/NLP\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting import-ipynb\n",
      "  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n",
      "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from import-ipynb) (5.5.0)\n",
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from import-ipynb) (5.4.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (1.0.18)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (2.6.1)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (4.8.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (4.4.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (57.4.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (0.8.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->import-ipynb) (0.2.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->import-ipynb) (1.15.0)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (2.16.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (4.3.3)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (4.11.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.18.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (5.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (4.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (4.12.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (22.1.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import-ipynb) (3.8.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->import-ipynb) (0.7.0)\n",
      "Installing collected packages: import-ipynb\n",
      "Successfully installed import-ipynb-0.1.4\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[K     |████████████████████████████████| 125 kB 33.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.5.1\n",
      "importing Jupyter notebook from vision_model_final_sol.ipynb\n",
      "importing Jupyter notebook from vision_dataset_final_sol.ipynb\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/NLP\n",
    "!pip install import-ipynb\n",
    "!pip install tensorboardX\n",
    "\n",
    "# TensorBoard를 사용하면 손실 및 정확도와 같은 측정 항목을 추적 및 시각화하는 것, 모델 그래프를 시각화하는 것, 히스토그램을 보는 것, 이미지를 출력하는 것 등이 가능\n",
    "import torch.utils.tensorboard as tensorboard \n",
    "import import_ipynb\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from vision_model_final_sol import Mini_Xception\n",
    "from vision_dataset_final_sol import create_train_dataloader, create_val_dataloader, create_test_dataloader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1660383871949,
     "user": {
      "displayName": "­권태희 / 학생 / 전기·정보공학부",
      "userId": "01216604526634043672"
     },
     "user_tz": -540
    },
    "id": "K4MVy9gRIkte"
   },
   "outputs": [],
   "source": [
    "seed_val = 2022\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 56393,
     "status": "error",
     "timestamp": 1660383974655,
     "user": {
      "displayName": "­권태희 / 학생 / 전기·정보공학부",
      "userId": "01216604526634043672"
     },
     "user_tz": -540
    },
    "id": "bRwnC0dcIktg",
    "outputId": "cdaba36d-aca2-4bd8-c663-d2bbcd892fa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training @ epoch 0 .. loss = 1.9318301677703857\n",
      "training @ epoch 0 .. loss = 1.5467197895050049\n",
      "training @ epoch 0 .. loss = 1.3518636226654053\n",
      "training @ epoch 0 .. loss = 1.6391366720199585\n",
      "training @ epoch 0 .. loss = 1.7041922807693481\n",
      "training @ epoch 0 .. loss = 1.642380952835083\n",
      "training @ epoch 0 .. loss = 2.0257010459899902\n",
      "training @ epoch 0 .. loss = 1.5268796682357788\n",
      "training @ epoch 0 .. loss = 1.7521225214004517\n",
      "training @ epoch 0 .. loss = 1.4879364967346191\n",
      "training @ epoch 0 .. loss = 1.9769564867019653\n",
      "training @ epoch 0 .. loss = 1.823913335800171\n",
      "training @ epoch 0 .. loss = 1.6838853359222412\n",
      "training @ epoch 0 .. loss = 1.9644886255264282\n",
      "training @ epoch 0 .. loss = 1.8103220462799072\n",
      "training @ epoch 0 .. loss = 1.6184837818145752\n",
      "training @ epoch 0 .. loss = 1.7821850776672363\n",
      "training @ epoch 0 .. loss = 1.798424243927002\n",
      "training @ epoch 0 .. loss = 1.8689876794815063\n",
      "training @ epoch 0 .. loss = 1.8685249090194702\n",
      "training @ epoch 0 .. loss = 1.6433125734329224\n",
      "training @ epoch 0 .. loss = 1.590511679649353\n",
      "training @ epoch 0 .. loss = 1.667346477508545\n",
      "training @ epoch 0 .. loss = 1.8055466413497925\n",
      "training @ epoch 0 .. loss = 1.5708175897598267\n",
      "training @ epoch 0 .. loss = 1.9130009412765503\n",
      "training @ epoch 0 .. loss = 1.8839396238327026\n",
      "training @ epoch 0 .. loss = 1.8423893451690674\n",
      "training @ epoch 0 .. loss = 1.7339649200439453\n",
      "training @ epoch 0 .. loss = 1.9471980333328247\n",
      "training @ epoch 0 .. loss = 2.2471742630004883\n",
      "training @ epoch 0 .. loss = 1.613034725189209\n",
      "training @ epoch 0 .. loss = 1.822295904159546\n",
      "training @ epoch 0 .. loss = 1.8068255186080933\n",
      "training @ epoch 0 .. loss = 1.8880010843276978\n",
      "training @ epoch 0 .. loss = 1.6258236169815063\n",
      "training @ epoch 0 .. loss = 1.9963765144348145\n",
      "training @ epoch 0 .. loss = 1.6393685340881348\n",
      "training @ epoch 0 .. loss = 1.655414342880249\n",
      "training @ epoch 0 .. loss = 1.8951119184494019\n",
      "training @ epoch 0 .. loss = 1.9002301692962646\n",
      "training @ epoch 0 .. loss = 1.9340322017669678\n",
      "training @ epoch 0 .. loss = 1.6436653137207031\n",
      "training @ epoch 0 .. loss = 1.7581382989883423\n",
      "training @ epoch 0 .. loss = 1.901084303855896\n",
      "training @ epoch 0 .. loss = 1.5652867555618286\n",
      "training @ epoch 0 .. loss = 1.5886489152908325\n",
      "training @ epoch 0 .. loss = 1.9334603548049927\n",
      "training @ epoch 0 .. loss = 1.6817718744277954\n",
      "training @ epoch 0 .. loss = 1.7125250101089478\n",
      "training @ epoch 0 .. loss = 1.597814917564392\n",
      "training @ epoch 0 .. loss = 1.737168788909912\n",
      "training @ epoch 0 .. loss = 1.5508846044540405\n",
      "training @ epoch 0 .. loss = 1.9643007516860962\n",
      "training @ epoch 0 .. loss = 1.722079873085022\n",
      "training @ epoch 0 .. loss = 1.6711384057998657\n",
      "training @ epoch 0 .. loss = 1.6946184635162354\n",
      "training @ epoch 0 .. loss = 1.9167938232421875\n",
      "training @ epoch 0 .. loss = 2.0963308811187744\n",
      "training @ epoch 0 .. loss = 1.8193516731262207\n",
      "training @ epoch 0 .. loss = 1.7596850395202637\n",
      "training @ epoch 0 .. loss = 1.3284062147140503\n",
      "training @ epoch 0 .. loss = 1.5284825563430786\n",
      "training @ epoch 0 .. loss = 1.9385510683059692\n",
      "training @ epoch 0 .. loss = 1.5816913843154907\n",
      "training @ epoch 0 .. loss = 1.8396130800247192\n",
      "training @ epoch 0 .. loss = 1.7223625183105469\n",
      "training @ epoch 0 .. loss = 1.8667892217636108\n",
      "training @ epoch 0 .. loss = 1.882190227508545\n",
      "training @ epoch 0 .. loss = 1.9602768421173096\n",
      "training @ epoch 0 .. loss = 1.7214019298553467\n",
      "training @ epoch 0 .. loss = 2.123985767364502\n",
      "training @ epoch 0 .. loss = 1.861149549484253\n",
      "training @ epoch 0 .. loss = 1.5658600330352783\n",
      "training @ epoch 0 .. loss = 1.5777992010116577\n",
      "training @ epoch 0 .. loss = 1.854696273803711\n",
      "training @ epoch 0 .. loss = 1.7234512567520142\n",
      "training @ epoch 0 .. loss = 1.6098341941833496\n",
      "training @ epoch 0 .. loss = 1.640467882156372\n",
      "training @ epoch 0 .. loss = 1.492705225944519\n",
      "training @ epoch 0 .. loss = 1.5478599071502686\n",
      "training @ epoch 0 .. loss = 1.7554281949996948\n",
      "training @ epoch 0 .. loss = 1.9036285877227783\n",
      "training @ epoch 0 .. loss = 1.455940842628479\n",
      "training @ epoch 0 .. loss = 1.751582384109497\n",
      "training @ epoch 0 .. loss = 1.838135838508606\n",
      "training @ epoch 0 .. loss = 2.123898506164551\n",
      "training @ epoch 0 .. loss = 1.7118945121765137\n",
      "training @ epoch 0 .. loss = 2.048285961151123\n",
      "training @ epoch 0 .. loss = 1.5845669507980347\n",
      "training @ epoch 0 .. loss = 1.6602897644042969\n",
      "training @ epoch 0 .. loss = 1.8402382135391235\n",
      "training @ epoch 0 .. loss = 1.783262014389038\n",
      "training @ epoch 0 .. loss = 1.4844938516616821\n",
      "training @ epoch 0 .. loss = 1.7648637294769287\n",
      "training @ epoch 0 .. loss = 1.6336944103240967\n",
      "training @ epoch 0 .. loss = 1.6061897277832031\n",
      "training @ epoch 0 .. loss = 1.9541232585906982\n",
      "training @ epoch 0 .. loss = 2.022383689880371\n",
      "training @ epoch 0 .. loss = 1.8126254081726074\n",
      "training @ epoch 0 .. loss = 1.9288161993026733\n",
      "training @ epoch 0 .. loss = 1.854519009590149\n",
      "training @ epoch 0 .. loss = 2.006091356277466\n",
      "training @ epoch 0 .. loss = 1.8256820440292358\n",
      "training @ epoch 0 .. loss = 1.6221524477005005\n",
      "training @ epoch 0 .. loss = 1.6386668682098389\n",
      "training @ epoch 0 .. loss = 1.7651336193084717\n",
      "training @ epoch 0 .. loss = 1.9180715084075928\n",
      "training @ epoch 0 .. loss = 1.8005403280258179\n",
      "training @ epoch 0 .. loss = 1.6907179355621338\n",
      "training @ epoch 0 .. loss = 1.8506428003311157\n",
      "training @ epoch 0 .. loss = 1.4487285614013672\n",
      "training @ epoch 0 .. loss = 1.5594980716705322\n",
      "training @ epoch 0 .. loss = 1.8358511924743652\n",
      "training @ epoch 0 .. loss = 1.6144253015518188\n",
      "training @ epoch 0 .. loss = 1.4378832578659058\n",
      "training @ epoch 0 .. loss = 1.9248127937316895\n",
      "training @ epoch 0 .. loss = 1.8350211381912231\n",
      "training @ epoch 0 .. loss = 2.1179821491241455\n",
      "training @ epoch 0 .. loss = 1.8464809656143188\n",
      "training @ epoch 0 .. loss = 1.6960129737854004\n",
      "training @ epoch 0 .. loss = 1.5998464822769165\n",
      "training @ epoch 0 .. loss = 1.7561895847320557\n",
      "training @ epoch 0 .. loss = 1.7134028673171997\n",
      "training @ epoch 0 .. loss = 1.5641350746154785\n",
      "training @ epoch 0 .. loss = 1.6116911172866821\n",
      "training @ epoch 0 .. loss = 1.7714588642120361\n",
      "training @ epoch 0 .. loss = 1.6452463865280151\n",
      "training @ epoch 0 .. loss = 1.847418189048767\n",
      "training @ epoch 0 .. loss = 1.8349565267562866\n",
      "training @ epoch 0 .. loss = 1.6801847219467163\n",
      "training @ epoch 0 .. loss = 1.6572617292404175\n",
      "training @ epoch 0 .. loss = 1.9907422065734863\n",
      "training @ epoch 0 .. loss = 1.4712834358215332\n",
      "training @ epoch 0 .. loss = 1.8631669282913208\n",
      "training @ epoch 0 .. loss = 1.9879868030548096\n",
      "training @ epoch 0 .. loss = 1.846662998199463\n",
      "training @ epoch 0 .. loss = 1.8200938701629639\n",
      "training @ epoch 0 .. loss = 2.0784895420074463\n",
      "training @ epoch 0 .. loss = 2.039498805999756\n",
      "training @ epoch 0 .. loss = 1.7977721691131592\n",
      "training @ epoch 0 .. loss = 1.8771737813949585\n",
      "training @ epoch 0 .. loss = 1.528151273727417\n",
      "training @ epoch 0 .. loss = 1.7213082313537598\n",
      "training @ epoch 0 .. loss = 1.7166752815246582\n",
      "training @ epoch 0 .. loss = 1.697782278060913\n",
      "training @ epoch 0 .. loss = 1.6314958333969116\n",
      "training @ epoch 0 .. loss = 1.6589064598083496\n",
      "training @ epoch 0 .. loss = 1.4405351877212524\n",
      "training @ epoch 0 .. loss = 1.7945436239242554\n",
      "training @ epoch 0 .. loss = 1.878543496131897\n",
      "training @ epoch 0 .. loss = 1.677599549293518\n",
      "training @ epoch 0 .. loss = 1.6142383813858032\n",
      "training @ epoch 0 .. loss = 1.7888128757476807\n",
      "training @ epoch 0 .. loss = 1.6541519165039062\n",
      "training @ epoch 0 .. loss = 1.8018227815628052\n",
      "training @ epoch 0 .. loss = 1.7898019552230835\n",
      "training @ epoch 0 .. loss = 1.8472819328308105\n",
      "training @ epoch 0 .. loss = 1.8092741966247559\n",
      "training @ epoch 0 .. loss = 1.6083766222000122\n",
      "training @ epoch 0 .. loss = 1.5780072212219238\n",
      "training @ epoch 0 .. loss = 1.852446436882019\n",
      "training @ epoch 0 .. loss = 1.7897850275039673\n",
      "training @ epoch 0 .. loss = 1.9678739309310913\n",
      "training @ epoch 0 .. loss = 1.8461518287658691\n",
      "training @ epoch 0 .. loss = 1.8307267427444458\n",
      "training @ epoch 0 .. loss = 1.6293293237686157\n",
      "training @ epoch 0 .. loss = 1.8698985576629639\n",
      "training @ epoch 0 .. loss = 1.8024688959121704\n",
      "training @ epoch 0 .. loss = 1.6195560693740845\n",
      "training @ epoch 0 .. loss = 1.8253707885742188\n",
      "training @ epoch 0 .. loss = 1.7695717811584473\n",
      "training @ epoch 0 .. loss = 1.6671793460845947\n",
      "training @ epoch 0 .. loss = 1.6434828042984009\n",
      "training @ epoch 0 .. loss = 1.6188026666641235\n",
      "training @ epoch 0 .. loss = 1.7129751443862915\n",
      "training @ epoch 0 .. loss = 1.7866673469543457\n",
      "training @ epoch 0 .. loss = 1.4861018657684326\n",
      "training @ epoch 0 .. loss = 1.6097557544708252\n",
      "training @ epoch 0 .. loss = 1.6785238981246948\n",
      "training @ epoch 0 .. loss = 1.6132460832595825\n",
      "training @ epoch 0 .. loss = 1.7814862728118896\n",
      "training @ epoch 0 .. loss = 1.5655238628387451\n",
      "training @ epoch 0 .. loss = 1.945249319076538\n",
      "training @ epoch 0 .. loss = 1.8712551593780518\n",
      "training @ epoch 0 .. loss = 1.5197246074676514\n",
      "training @ epoch 0 .. loss = 2.149158477783203\n",
      "training @ epoch 0 .. loss = 1.5882352590560913\n",
      "training @ epoch 0 .. loss = 1.8237277269363403\n",
      "training @ epoch 0 .. loss = 1.7704235315322876\n",
      "training @ epoch 0 .. loss = 1.9370055198669434\n",
      "training @ epoch 0 .. loss = 1.8399105072021484\n",
      "training @ epoch 0 .. loss = 2.051912546157837\n",
      "training @ epoch 0 .. loss = 1.8920809030532837\n",
      "training @ epoch 0 .. loss = 1.9746413230895996\n",
      "training @ epoch 0 .. loss = 1.5990231037139893\n",
      "training @ epoch 0 .. loss = 1.7681206464767456\n",
      "training @ epoch 0 .. loss = 1.5452643632888794\n",
      "training @ epoch 0 .. loss = 1.6448694467544556\n",
      "training @ epoch 0 .. loss = 1.7059459686279297\n",
      "training @ epoch 0 .. loss = 1.810943603515625\n",
      "training @ epoch 0 .. loss = 1.611596703529358\n",
      "training @ epoch 0 .. loss = 1.6041622161865234\n",
      "training @ epoch 0 .. loss = 1.7587945461273193\n",
      "training @ epoch 0 .. loss = 1.6683400869369507\n",
      "training @ epoch 0 .. loss = 1.6536310911178589\n",
      "training @ epoch 0 .. loss = 1.9436967372894287\n",
      "training @ epoch 0 .. loss = 1.6591150760650635\n",
      "training @ epoch 0 .. loss = 1.6056796312332153\n",
      "training @ epoch 0 .. loss = 1.8065788745880127\n",
      "training @ epoch 0 .. loss = 1.5123287439346313\n",
      "training @ epoch 0 .. loss = 1.7013214826583862\n",
      "training @ epoch 0 .. loss = 1.5021740198135376\n",
      "training @ epoch 0 .. loss = 1.828061819076538\n",
      "training @ epoch 0 .. loss = 1.5877125263214111\n",
      "training @ epoch 0 .. loss = 1.5317378044128418\n",
      "training @ epoch 0 .. loss = 1.5409276485443115\n",
      "training @ epoch 0 .. loss = 1.6818546056747437\n",
      "training @ epoch 0 .. loss = 1.5976890325546265\n",
      "training @ epoch 0 .. loss = 1.8933848142623901\n",
      "training @ epoch 0 .. loss = 1.7764418125152588\n",
      "training @ epoch 0 .. loss = 1.6916016340255737\n",
      "training @ epoch 0 .. loss = 1.6473129987716675\n",
      "training @ epoch 0 .. loss = 1.5556479692459106\n",
      "training @ epoch 0 .. loss = 1.3884960412979126\n",
      "training @ epoch 0 .. loss = 1.6738721132278442\n",
      "training @ epoch 0 .. loss = 1.6392371654510498\n",
      "training @ epoch 0 .. loss = 1.633898138999939\n",
      "training @ epoch 0 .. loss = 1.6723812818527222\n",
      "training @ epoch 0 .. loss = 1.8866883516311646\n",
      "training @ epoch 0 .. loss = 1.6805107593536377\n",
      "training @ epoch 0 .. loss = 1.79864501953125\n",
      "training @ epoch 0 .. loss = 1.3166139125823975\n",
      "training @ epoch 0 .. loss = 1.5674816370010376\n",
      "training @ epoch 0 .. loss = 1.793212652206421\n",
      "training @ epoch 0 .. loss = 1.6900008916854858\n",
      "training @ epoch 0 .. loss = 1.8428007364273071\n",
      "training @ epoch 0 .. loss = 1.7676018476486206\n",
      "training @ epoch 0 .. loss = 1.7861248254776\n",
      "training @ epoch 0 .. loss = 1.80775785446167\n",
      "training @ epoch 0 .. loss = 1.5536460876464844\n",
      "training @ epoch 0 .. loss = 1.762623906135559\n",
      "training @ epoch 0 .. loss = 1.7192511558532715\n",
      "training @ epoch 0 .. loss = 1.7374495267868042\n",
      "training @ epoch 0 .. loss = 1.7840323448181152\n",
      "training @ epoch 0 .. loss = 1.6464358568191528\n",
      "training @ epoch 0 .. loss = 1.451485276222229\n",
      "training @ epoch 0 .. loss = 1.9046318531036377\n",
      "training @ epoch 0 .. loss = 1.6744450330734253\n",
      "training @ epoch 0 .. loss = 1.8708889484405518\n",
      "training @ epoch 0 .. loss = 1.7974106073379517\n",
      "training @ epoch 0 .. loss = 1.6964887380599976\n",
      "training @ epoch 0 .. loss = 1.5092494487762451\n",
      "training @ epoch 0 .. loss = 1.7095059156417847\n",
      "training @ epoch 0 .. loss = 1.5037673711776733\n",
      "training @ epoch 0 .. loss = 1.6628941297531128\n",
      "training @ epoch 0 .. loss = 2.0591721534729004\n",
      "training @ epoch 0 .. loss = 1.5215182304382324\n",
      "training @ epoch 0 .. loss = 2.018399477005005\n",
      "training @ epoch 0 .. loss = 1.5438340902328491\n",
      "training @ epoch 0 .. loss = 1.701360821723938\n",
      "training @ epoch 0 .. loss = 1.5128440856933594\n",
      "training @ epoch 0 .. loss = 1.5869560241699219\n",
      "training @ epoch 0 .. loss = 1.735144019126892\n",
      "training @ epoch 0 .. loss = 1.3953133821487427\n",
      "training @ epoch 0 .. loss = 1.41005539894104\n",
      "training @ epoch 0 .. loss = 1.5695708990097046\n",
      "training @ epoch 0 .. loss = 1.7803539037704468\n",
      "training @ epoch 0 .. loss = 1.8426998853683472\n",
      "training @ epoch 0 .. loss = 1.420055627822876\n",
      "training @ epoch 0 .. loss = 1.55642831325531\n",
      "training @ epoch 0 .. loss = 2.0128307342529297\n",
      "training @ epoch 0 .. loss = 1.8704501390457153\n",
      "training @ epoch 0 .. loss = 2.0081937313079834\n",
      "training @ epoch 0 .. loss = 1.7563785314559937\n",
      "training @ epoch 0 .. loss = 1.488449215888977\n",
      "training @ epoch 0 .. loss = 1.8227702379226685\n",
      "training @ epoch 0 .. loss = 1.9544289112091064\n",
      "training @ epoch 0 .. loss = 1.6155377626419067\n",
      "training @ epoch 0 .. loss = 1.599845290184021\n",
      "training @ epoch 0 .. loss = 1.4699461460113525\n",
      "training @ epoch 0 .. loss = 1.6881310939788818\n",
      "training @ epoch 0 .. loss = 1.4152520895004272\n",
      "training @ epoch 0 .. loss = 2.062868356704712\n",
      "training @ epoch 0 .. loss = 1.5950175523757935\n",
      "training @ epoch 0 .. loss = 1.6072161197662354\n",
      "training @ epoch 0 .. loss = 1.5819159746170044\n",
      "training @ epoch 0 .. loss = 1.6821635961532593\n",
      "training @ epoch 0 .. loss = 1.5860990285873413\n",
      "training @ epoch 0 .. loss = 1.6821281909942627\n",
      "training @ epoch 0 .. loss = 1.7656404972076416\n",
      "training @ epoch 0 .. loss = 1.9226317405700684\n",
      "training @ epoch 0 .. loss = 1.827146291732788\n",
      "training @ epoch 0 .. loss = 1.9319641590118408\n",
      "training @ epoch 0 .. loss = 1.6777094602584839\n",
      "training @ epoch 0 .. loss = 1.9466173648834229\n",
      "training @ epoch 0 .. loss = 1.8162117004394531\n",
      "training @ epoch 0 .. loss = 1.8099076747894287\n",
      "training @ epoch 0 .. loss = 1.7862247228622437\n",
      "training @ epoch 0 .. loss = 1.8748899698257446\n",
      "training @ epoch 0 .. loss = 1.536236047744751\n",
      "training @ epoch 0 .. loss = 1.6145108938217163\n",
      "training @ epoch 0 .. loss = 1.7503143548965454\n",
      "training @ epoch 0 .. loss = 1.9085743427276611\n",
      "training @ epoch 0 .. loss = 1.4763134717941284\n",
      "training @ epoch 0 .. loss = 1.7714091539382935\n",
      "training @ epoch 0 .. loss = 1.6455157995224\n",
      "training @ epoch 0 .. loss = 1.7890522480010986\n",
      "training @ epoch 0 .. loss = 1.922939419746399\n",
      "training @ epoch 0 .. loss = 1.8504750728607178\n",
      "training @ epoch 0 .. loss = 1.3846485614776611\n",
      "training @ epoch 0 .. loss = 1.7976423501968384\n",
      "training @ epoch 0 .. loss = 1.921746015548706\n",
      "training @ epoch 0 .. loss = 1.7634979486465454\n",
      "training @ epoch 0 .. loss = 1.9723824262619019\n",
      "training @ epoch 0 .. loss = 1.977033257484436\n",
      "training @ epoch 0 .. loss = 1.5440647602081299\n",
      "training @ epoch 0 .. loss = 1.5509358644485474\n",
      "training @ epoch 0 .. loss = 1.5507283210754395\n",
      "training @ epoch 0 .. loss = 1.7913076877593994\n",
      "training @ epoch 0 .. loss = 1.5988872051239014\n",
      "training @ epoch 0 .. loss = 1.6513406038284302\n",
      "training @ epoch 0 .. loss = 1.4986366033554077\n",
      "training @ epoch 0 .. loss = 1.4343202114105225\n",
      "training @ epoch 0 .. loss = 1.7477701902389526\n",
      "training @ epoch 0 .. loss = 1.6043835878372192\n",
      "training @ epoch 0 .. loss = 1.6400370597839355\n",
      "training @ epoch 0 .. loss = 1.8558433055877686\n",
      "training @ epoch 0 .. loss = 1.671128511428833\n",
      "training @ epoch 0 .. loss = 1.6825305223464966\n",
      "training @ epoch 0 .. loss = 1.8871586322784424\n",
      "training @ epoch 0 .. loss = 1.7723419666290283\n",
      "training @ epoch 0 .. loss = 1.8059026002883911\n",
      "training @ epoch 0 .. loss = 1.6057684421539307\n",
      "training @ epoch 0 .. loss = 1.543925166130066\n",
      "training @ epoch 0 .. loss = 1.5608264207839966\n",
      "training @ epoch 0 .. loss = 1.4262627363204956\n",
      "training @ epoch 0 .. loss = 1.550235629081726\n",
      "training @ epoch 0 .. loss = 1.7050743103027344\n",
      "training @ epoch 0 .. loss = 1.6331418752670288\n",
      "training @ epoch 0 .. loss = 1.7284499406814575\n",
      "training @ epoch 0 .. loss = 1.7580734491348267\n",
      "training @ epoch 0 .. loss = 1.5762652158737183\n",
      "training @ epoch 0 .. loss = 1.5585728883743286\n",
      "training @ epoch 0 .. loss = 1.6512467861175537\n",
      "training @ epoch 0 .. loss = 1.77983558177948\n",
      "training @ epoch 0 .. loss = 1.6687523126602173\n",
      "training @ epoch 0 .. loss = 1.945579171180725\n",
      "training @ epoch 0 .. loss = 1.8644545078277588\n",
      "training @ epoch 0 .. loss = 1.6237043142318726\n",
      "training @ epoch 0 .. loss = 1.487460732460022\n",
      "training @ epoch 0 .. loss = 1.8960481882095337\n",
      "training @ epoch 0 .. loss = 1.8070542812347412\n",
      "training @ epoch 0 .. loss = 1.8058611154556274\n",
      "training @ epoch 0 .. loss = 1.6277142763137817\n",
      "training @ epoch 0 .. loss = 1.6712112426757812\n",
      "training @ epoch 0 .. loss = 1.806753158569336\n",
      "training @ epoch 0 .. loss = 1.7560068368911743\n",
      "training @ epoch 0 .. loss = 1.889095664024353\n",
      "training @ epoch 0 .. loss = 1.6676344871520996\n",
      "training @ epoch 0 .. loss = 1.495626449584961\n",
      "training @ epoch 0 .. loss = 1.7265111207962036\n",
      "training @ epoch 0 .. loss = 2.0306708812713623\n",
      "training @ epoch 0 .. loss = 1.609316349029541\n",
      "training @ epoch 0 .. loss = 1.903062343597412\n",
      "training @ epoch 0 .. loss = 1.6956160068511963\n",
      "training @ epoch 0 .. loss = 1.7848637104034424\n",
      "training @ epoch 0 .. loss = 1.5754623413085938\n",
      "training @ epoch 0 .. loss = 1.6008638143539429\n",
      "training @ epoch 0 .. loss = 1.6428322792053223\n",
      "training @ epoch 0 .. loss = 1.6692235469818115\n",
      "training @ epoch 0 .. loss = 1.6477837562561035\n",
      "training @ epoch 0 .. loss = 1.6408851146697998\n",
      "training @ epoch 0 .. loss = 1.4240955114364624\n",
      "training @ epoch 0 .. loss = 1.9673666954040527\n",
      "training @ epoch 0 .. loss = 1.812168836593628\n",
      "training @ epoch 0 .. loss = 2.092593193054199\n",
      "training @ epoch 0 .. loss = 1.8008204698562622\n",
      "training @ epoch 0 .. loss = 1.5230886936187744\n",
      "training @ epoch 0 .. loss = 1.869675874710083\n",
      "training @ epoch 0 .. loss = 1.528860092163086\n",
      "training @ epoch 0 .. loss = 2.1121017932891846\n",
      "training @ epoch 0 .. loss = 1.6948463916778564\n",
      "training @ epoch 0 .. loss = 1.5017262697219849\n",
      "training @ epoch 0 .. loss = 1.6639766693115234\n",
      "training @ epoch 0 .. loss = 1.9724684953689575\n",
      "training @ epoch 0 .. loss = 1.8191395998001099\n",
      "training @ epoch 0 .. loss = 1.7102605104446411\n",
      "training @ epoch 0 .. loss = 1.5306230783462524\n",
      "training @ epoch 0 .. loss = 1.5641052722930908\n",
      "training @ epoch 0 .. loss = 1.7208335399627686\n",
      "training @ epoch 0 .. loss = 1.4610828161239624\n",
      "training @ epoch 0 .. loss = 1.8596291542053223\n",
      "training @ epoch 0 .. loss = 1.6050301790237427\n",
      "training @ epoch 0 .. loss = 1.4902700185775757\n",
      "training @ epoch 0 .. loss = 1.4403480291366577\n",
      "training @ epoch 0 .. loss = 1.8017081022262573\n",
      "training @ epoch 0 .. loss = 1.6323455572128296\n",
      "training @ epoch 0 .. loss = 1.8836307525634766\n",
      "training @ epoch 0 .. loss = 1.5999209880828857\n",
      "training @ epoch 0 .. loss = 1.7984237670898438\n",
      "training @ epoch 0 .. loss = 2.005537509918213\n",
      "training @ epoch 0 .. loss = 1.8897441625595093\n",
      "training @ epoch 0 .. loss = 1.6497925519943237\n",
      "training @ epoch 0 .. loss = 1.618625521659851\n",
      "training @ epoch 0 .. loss = 1.4991790056228638\n",
      "training @ epoch 0 .. loss = 1.6489711999893188\n",
      "training @ epoch 0 .. loss = 2.0609586238861084\n",
      "training @ epoch 0 .. loss = 1.662793755531311\n",
      "training @ epoch 0 .. loss = 1.6274266242980957\n",
      "training @ epoch 0 .. loss = 1.9514774084091187\n",
      "training @ epoch 0 .. loss = 1.8049875497817993\n",
      "training @ epoch 0 .. loss = 1.6882737874984741\n",
      "training @ epoch 0 .. loss = 1.7068772315979004\n",
      "training @ epoch 0 .. loss = 1.5642799139022827\n",
      "training @ epoch 0 .. loss = 1.3864604234695435\n",
      "training @ epoch 0 .. loss = 1.6151615381240845\n",
      "training @ epoch 0 .. loss = 1.5089665651321411\n",
      "training @ epoch 0 .. loss = 1.7039629220962524\n",
      "training @ epoch 0 .. loss = 1.8003915548324585\n",
      "training @ epoch 0 .. loss = 1.4888025522232056\n",
      "training @ epoch 0 .. loss = 1.8117059469223022\n",
      "training @ epoch 0 .. loss = 2.073166608810425\n",
      "training @ epoch 0 .. loss = 1.4654330015182495\n",
      "training @ epoch 0 .. loss = 1.4614418745040894\n",
      "training @ epoch 0 .. loss = 1.2031311988830566\n",
      "training @ epoch 0 .. loss = 1.6255723237991333\n",
      "training @ epoch 0 .. loss = 1.92035710811615\n",
      "training @ epoch 0 .. loss = 1.785961627960205\n",
      "training @ epoch 0 .. loss = 1.6235294342041016\n",
      "training @ epoch 0 .. loss = 1.4538227319717407\n",
      "training @ epoch 0 .. loss = 2.1607561111450195\n",
      "training @ epoch 0 .. loss = 1.743861436843872\n",
      "training @ epoch 0 .. loss = 2.0293972492218018\n",
      "training @ epoch 0 .. loss = 1.9328453540802002\n",
      "training @ epoch 0 .. loss = 1.7760080099105835\n",
      "training @ epoch 0 .. loss = 1.4786460399627686\n",
      "training @ epoch 0 .. loss = 1.8935543298721313\n",
      "training @ epoch 0 .. loss = 1.6525477170944214\n",
      "training @ epoch 0 .. loss = 1.7274900674819946\n",
      "training @ epoch 0 .. loss = 1.8575412034988403\n",
      "training @ epoch 0 .. loss = 1.7643887996673584\n",
      "training @ epoch 0 .. loss = 1.8797599077224731\n",
      "training @ epoch 0 .. loss = 1.5073446035385132\n",
      "training @ epoch 0 .. loss = 1.705203652381897\n",
      "training @ epoch 0 .. loss = 1.6366373300552368\n",
      "training @ epoch 0 .. loss = 1.5698133707046509\n",
      "training @ epoch 0 .. loss = 1.7134329080581665\n",
      "training @ epoch 0 .. loss = 1.8045974969863892\n",
      "training @ epoch 0 .. loss = 1.7910292148590088\n",
      "training @ epoch 0 .. loss = 1.6647706031799316\n",
      "training @ epoch 0 .. loss = 1.6268197298049927\n",
      "training @ epoch 0 .. loss = 1.4750994443893433\n",
      "training @ epoch 0 .. loss = 1.4836580753326416\n",
      "training @ epoch 0 .. loss = 1.709801435470581\n",
      "training @ epoch 0 .. loss = 1.7420213222503662\n",
      "training @ epoch 0 .. loss = 1.6436504125595093\n",
      "training @ epoch 0 .. loss = 1.4177380800247192\n",
      "training @ epoch 0 .. loss = 1.6038874387741089\n",
      "training @ epoch 0 .. loss = 1.9245389699935913\n",
      "training @ epoch 0 .. loss = 1.9368398189544678\n",
      "training @ epoch 0 .. loss = 1.2212936878204346\n",
      "training @ epoch 0 .. loss = 1.5369099378585815\n",
      "training @ epoch 0 .. loss = 1.9817475080490112\n",
      "training @ epoch 0 .. loss = 1.512484073638916\n",
      "training @ epoch 0 .. loss = 1.9354947805404663\n",
      "training @ epoch 0 .. loss = 1.8729413747787476\n",
      "training @ epoch 0 .. loss = 1.3798855543136597\n",
      "training @ epoch 0 .. loss = 1.483802080154419\n",
      "training @ epoch 0 .. loss = 1.489471197128296\n",
      "training @ epoch 0 .. loss = 1.7452967166900635\n",
      "training @ epoch 0 .. loss = 1.7573808431625366\n",
      "training @ epoch 0 .. loss = 1.3429124355316162\n",
      "training @ epoch 0 .. loss = 1.9401952028274536\n",
      "training @ epoch 0 .. loss = 1.974542260169983\n",
      "training @ epoch 0 .. loss = 1.6577156782150269\n",
      "training @ epoch 0 .. loss = 1.7442100048065186\n",
      "training @ epoch 0 .. loss = 1.680812120437622\n",
      "training @ epoch 0 .. loss = 1.9512808322906494\n",
      "training @ epoch 0 .. loss = 1.7416621446609497\n",
      "training @ epoch 0 .. loss = 1.478502631187439\n",
      "training @ epoch 0 .. loss = 1.7794115543365479\n",
      "training @ epoch 0 .. loss = 1.6690800189971924\n",
      "training @ epoch 0 .. loss = 1.7023192644119263\n",
      "training @ epoch 0 .. loss = 1.4742783308029175\n",
      "training @ epoch 0 .. loss = 1.3302468061447144\n",
      "training @ epoch 0 .. loss = 1.4954835176467896\n",
      "training @ epoch 0 .. loss = 1.5760109424591064\n",
      "training @ epoch 0 .. loss = 1.9275249242782593\n",
      "training @ epoch 0 .. loss = 1.541585922241211\n",
      "training @ epoch 0 .. loss = 1.209043264389038\n",
      "training @ epoch 0 .. loss = 1.406686782836914\n",
      "training @ epoch 0 .. loss = 1.237869381904602\n",
      "training @ epoch 0 .. loss = 1.851319432258606\n",
      "training @ epoch 0 .. loss = 1.3896090984344482\n",
      "training @ epoch 0 .. loss = 1.7053260803222656\n",
      "training @ epoch 0 .. loss = 1.6891034841537476\n",
      "training @ epoch 0 .. loss = 2.143084764480591\n",
      "training @ epoch 0 .. loss = 1.7158976793289185\n",
      "training @ epoch 0 .. loss = 1.8074198961257935\n",
      "training @ epoch 0 .. loss = 1.5737117528915405\n",
      "training @ epoch 0 .. loss = 1.7092607021331787\n",
      "training @ epoch 0 .. loss = 1.8023467063903809\n",
      "training @ epoch 0 .. loss = 1.5445663928985596\n",
      "training @ epoch 0 .. loss = 1.4010950326919556\n",
      "training @ epoch 0 .. loss = 1.6194708347320557\n",
      "training @ epoch 0 .. loss = 1.7742431163787842\n",
      "training @ epoch 0 .. loss = 1.529802918434143\n",
      "training @ epoch 0 .. loss = 1.466330885887146\n",
      "training @ epoch 0 .. loss = 1.8079476356506348\n",
      "training @ epoch 0 .. loss = 1.7299669981002808\n",
      "training @ epoch 0 .. loss = 1.9105287790298462\n",
      "training @ epoch 0 .. loss = 1.559338927268982\n",
      "training @ epoch 0 .. loss = 1.5947953462600708\n",
      "training @ epoch 0 .. loss = 1.780881643295288\n",
      "training @ epoch 0 .. loss = 1.5200186967849731\n",
      "training @ epoch 0 .. loss = 1.6313800811767578\n",
      "training @ epoch 0 .. loss = 1.6053268909454346\n",
      "training @ epoch 0 .. loss = 1.5176479816436768\n",
      "training @ epoch 0 .. loss = 1.71786367893219\n",
      "training @ epoch 0 .. loss = 1.853821873664856\n",
      "training @ epoch 0 .. loss = 2.1401076316833496\n",
      "training @ epoch 0 .. loss = 1.5955835580825806\n",
      "training @ epoch 0 .. loss = 1.8464738130569458\n",
      "training @ epoch 0 .. loss = 1.5664637088775635\n",
      "training @ epoch 0 .. loss = 1.7265629768371582\n",
      "training @ epoch 0 .. loss = 1.8029757738113403\n",
      "training @ epoch 0 .. loss = 1.52321457862854\n",
      "training @ epoch 0 .. loss = 1.8622723817825317\n",
      "training @ epoch 0 .. loss = 1.5737181901931763\n",
      "training @ epoch 0 .. loss = 1.4989811182022095\n",
      "training @ epoch 0 .. loss = 1.4311326742172241\n",
      "training @ epoch 0 .. loss = 1.6791845560073853\n",
      "training @ epoch 0 .. loss = 1.8482636213302612\n",
      "training @ epoch 0 .. loss = 1.8526564836502075\n",
      "training @ epoch 0 .. loss = 1.41703462600708\n",
      "training @ epoch 0 .. loss = 1.6716418266296387\n",
      "training @ epoch 0 .. loss = 2.0668530464172363\n",
      "training @ epoch 0 .. loss = 1.612151861190796\n",
      "training @ epoch 0 .. loss = 1.6529680490493774\n",
      "training @ epoch 0 .. loss = 2.006826639175415\n",
      "training @ epoch 0 .. loss = 1.625744104385376\n",
      "training @ epoch 0 .. loss = 1.6678637266159058\n",
      "training @ epoch 0 .. loss = 1.491562008857727\n",
      "training @ epoch 0 .. loss = 1.6124197244644165\n",
      "training @ epoch 0 .. loss = 1.6615656614303589\n",
      "training @ epoch 0 .. loss = 1.6063278913497925\n",
      "training @ epoch 0 .. loss = 1.6122393608093262\n",
      "training @ epoch 0 .. loss = 1.6958881616592407\n",
      "training @ epoch 0 .. loss = 1.5441880226135254\n",
      "training @ epoch 0 .. loss = 1.634864330291748\n",
      "training @ epoch 0 .. loss = 1.6301310062408447\n",
      "training @ epoch 0 .. loss = 1.7157496213912964\n",
      "training @ epoch 0 .. loss = 1.5986363887786865\n",
      "training @ epoch 0 .. loss = 1.6289746761322021\n",
      "training @ epoch 0 .. loss = 1.4473553895950317\n",
      "training @ epoch 0 .. loss = 1.5541325807571411\n",
      "training @ epoch 0 .. loss = 1.8685938119888306\n",
      "training @ epoch 0 .. loss = 1.5574361085891724\n",
      "training @ epoch 0 .. loss = 1.4666736125946045\n",
      "training @ epoch 0 .. loss = 1.6276804208755493\n",
      "training @ epoch 0 .. loss = 1.5319271087646484\n",
      "training @ epoch 0 .. loss = 1.7501863241195679\n",
      "training @ epoch 0 .. loss = 1.5837557315826416\n",
      "training @ epoch 0 .. loss = 1.586812138557434\n",
      "training @ epoch 0 .. loss = 1.8558772802352905\n",
      "training @ epoch 0 .. loss = 1.534488320350647\n",
      "training @ epoch 0 .. loss = 1.6451809406280518\n",
      "training @ epoch 0 .. loss = 1.784767985343933\n",
      "training @ epoch 0 .. loss = 1.57249116897583\n",
      "training @ epoch 0 .. loss = 2.024385929107666\n",
      "training @ epoch 0 .. loss = 1.5556623935699463\n",
      "training @ epoch 0 .. loss = 1.765865683555603\n",
      "training @ epoch 0 .. loss = 1.7027837038040161\n",
      "training @ epoch 0 .. loss = 1.5658155679702759\n",
      "training @ epoch 0 .. loss = 1.504860758781433\n",
      "training @ epoch 0 .. loss = 1.6274229288101196\n",
      "training @ epoch 0 .. loss = 1.7749730348587036\n",
      "training @ epoch 0 .. loss = 1.9296497106552124\n",
      "training @ epoch 0 .. loss = 1.6383107900619507\n",
      "training @ epoch 0 .. loss = 1.9168319702148438\n",
      "training @ epoch 0 .. loss = 1.5817666053771973\n",
      "training @ epoch 0 .. loss = 1.6387439966201782\n",
      "training @ epoch 0 .. loss = 1.4988160133361816\n",
      "training @ epoch 0 .. loss = 1.714916706085205\n",
      "training @ epoch 0 .. loss = 1.6021305322647095\n",
      "training @ epoch 0 .. loss = 1.732015609741211\n",
      "training @ epoch 0 .. loss = 1.9670246839523315\n",
      "training @ epoch 0 .. loss = 1.604478359222412\n",
      "training @ epoch 0 .. loss = 2.050851345062256\n",
      "training @ epoch 0 .. loss = 1.6150976419448853\n",
      "training @ epoch 0 .. loss = 1.5029304027557373\n",
      "training @ epoch 0 .. loss = 1.7174180746078491\n",
      "training @ epoch 0 .. loss = 1.3905127048492432\n",
      "training @ epoch 0 .. loss = 1.8346211910247803\n",
      "training @ epoch 0 .. loss = 1.8848347663879395\n",
      "training @ epoch 0 .. loss = 1.8948783874511719\n",
      "training @ epoch 0 .. loss = 1.5846621990203857\n",
      "training @ epoch 0 .. loss = 1.6638317108154297\n",
      "training @ epoch 0 .. loss = 1.4424992799758911\n",
      "training @ epoch 0 .. loss = 1.6236649751663208\n",
      "training @ epoch 0 .. loss = 1.725730538368225\n",
      "training @ epoch 0 .. loss = 1.4964983463287354\n",
      "training @ epoch 0 .. loss = 1.5234125852584839\n",
      "training @ epoch 0 .. loss = 1.91413414478302\n",
      "training @ epoch 0 .. loss = 1.5875078439712524\n",
      "training @ epoch 0 .. loss = 2.019561767578125\n",
      "training @ epoch 0 .. loss = 1.5334093570709229\n",
      "training @ epoch 0 .. loss = 2.006394147872925\n",
      "training @ epoch 0 .. loss = 1.9575295448303223\n",
      "training @ epoch 0 .. loss = 1.6041760444641113\n",
      "training @ epoch 0 .. loss = 1.689940094947815\n",
      "training @ epoch 0 .. loss = 1.7928862571716309\n",
      "training @ epoch 0 .. loss = 1.4867630004882812\n",
      "training @ epoch 0 .. loss = 1.4859693050384521\n",
      "training @ epoch 0 .. loss = 1.8814258575439453\n",
      "training @ epoch 0 .. loss = 1.643876314163208\n",
      "training @ epoch 0 .. loss = 1.8345435857772827\n",
      "training @ epoch 0 .. loss = 1.5094070434570312\n",
      "training @ epoch 0 .. loss = 1.4026399850845337\n",
      "training @ epoch 0 .. loss = 1.41943359375\n",
      "training @ epoch 0 .. loss = 1.681833267211914\n",
      "training @ epoch 0 .. loss = 1.6928452253341675\n",
      "training @ epoch 0 .. loss = 1.5637255907058716\n",
      "training @ epoch 0 .. loss = 1.509864091873169\n",
      "training @ epoch 0 .. loss = 1.5532028675079346\n",
      "training @ epoch 0 .. loss = 1.5981919765472412\n",
      "training @ epoch 0 .. loss = 1.5756298303604126\n",
      "training @ epoch 0 .. loss = 1.6537132263183594\n",
      "training @ epoch 0 .. loss = 1.909257173538208\n",
      "training @ epoch 0 .. loss = 1.6699142456054688\n",
      "training @ epoch 0 .. loss = 1.4627153873443604\n",
      "training @ epoch 0 .. loss = 1.7404011487960815\n",
      "training @ epoch 0 .. loss = 1.7144886255264282\n",
      "training @ epoch 0 .. loss = 1.4809277057647705\n",
      "training @ epoch 0 .. loss = 1.654826283454895\n",
      "training @ epoch 0 .. loss = 1.9331117868423462\n",
      "training @ epoch 0 .. loss = 1.601313829421997\n",
      "training @ epoch 0 .. loss = 1.422137975692749\n",
      "training @ epoch 0 .. loss = 1.542211651802063\n",
      "training @ epoch 0 .. loss = 1.4915015697479248\n",
      "training @ epoch 0 .. loss = 1.4508603811264038\n",
      "training @ epoch 0 .. loss = 1.3272391557693481\n",
      "training @ epoch 0 .. loss = 1.7213455438613892\n",
      "training @ epoch 0 .. loss = 1.772882103919983\n",
      "training @ epoch 0 .. loss = 2.001126289367676\n",
      "training @ epoch 0 .. loss = 1.9211623668670654\n",
      "training @ epoch 0 .. loss = 1.3164458274841309\n",
      "training @ epoch 0 .. loss = 1.791776180267334\n",
      "training @ epoch 0 .. loss = 1.5982428789138794\n",
      "training @ epoch 0 .. loss = 1.4418559074401855\n",
      "training @ epoch 0 .. loss = 1.9206843376159668\n",
      "training @ epoch 0 .. loss = 1.567172646522522\n",
      "training @ epoch 0 .. loss = 1.6328448057174683\n",
      "training @ epoch 0 .. loss = 1.5047324895858765\n",
      "training @ epoch 0 .. loss = 1.9039641618728638\n",
      "training @ epoch 0 .. loss = 1.588438868522644\n",
      "training @ epoch 0 .. loss = 1.6088122129440308\n",
      "training @ epoch 0 .. loss = 1.8838868141174316\n",
      "training @ epoch 0 .. loss = 1.4978233575820923\n",
      "training @ epoch 0 .. loss = 1.6642040014266968\n",
      "training @ epoch 0 .. loss = 1.685539722442627\n",
      "training @ epoch 0 .. loss = 1.4044049978256226\n",
      "training @ epoch 0 .. loss = 1.6422008275985718\n",
      "training @ epoch 0 .. loss = 1.6512113809585571\n",
      "training @ epoch 0 .. loss = 2.118696689605713\n",
      "training @ epoch 0 .. loss = 1.633780598640442\n",
      "training @ epoch 0 .. loss = 1.739086627960205\n",
      "training @ epoch 0 .. loss = 1.6598118543624878\n",
      "training @ epoch 0 .. loss = 1.5896245241165161\n",
      "training @ epoch 0 .. loss = 1.675034999847412\n",
      "training @ epoch 0 .. loss = 1.5802991390228271\n",
      "training @ epoch 0 .. loss = 1.9455691576004028\n",
      "training @ epoch 0 .. loss = 1.6964648962020874\n",
      "training @ epoch 0 .. loss = 1.6277692317962646\n",
      "training @ epoch 0 .. loss = 1.6622570753097534\n",
      "training @ epoch 0 .. loss = 2.166792631149292\n",
      "training @ epoch 0 .. loss = 1.7193583250045776\n",
      "training @ epoch 0 .. loss = 1.4616392850875854\n",
      "training @ epoch 0 .. loss = 1.709557294845581\n",
      "training @ epoch 0 .. loss = 1.393320918083191\n",
      "training @ epoch 0 .. loss = 1.391852855682373\n",
      "training @ epoch 0 .. loss = 1.5677894353866577\n",
      "training @ epoch 0 .. loss = 1.774917721748352\n",
      "training @ epoch 0 .. loss = 1.8511183261871338\n",
      "training @ epoch 0 .. loss = 1.9810892343521118\n",
      "training @ epoch 0 .. loss = 1.493652105331421\n",
      "training @ epoch 0 .. loss = 1.8928576707839966\n",
      "training @ epoch 0 .. loss = 1.8651506900787354\n",
      "training @ epoch 0 .. loss = 1.65946626663208\n",
      "training @ epoch 0 .. loss = 1.5164010524749756\n",
      "training @ epoch 0 .. loss = 1.9570486545562744\n",
      "training @ epoch 0 .. loss = 1.5188301801681519\n",
      "training @ epoch 0 .. loss = 1.4187119007110596\n",
      "training @ epoch 0 .. loss = 1.5250967741012573\n",
      "training @ epoch 0 .. loss = 1.340286135673523\n",
      "training @ epoch 0 .. loss = 1.6177024841308594\n",
      "training @ epoch 0 .. loss = 1.6121139526367188\n",
      "training @ epoch 0 .. loss = 1.5582815408706665\n",
      "training @ epoch 0 .. loss = 1.7028952836990356\n",
      "training @ epoch 0 .. loss = 1.6349329948425293\n",
      "training @ epoch 0 .. loss = 1.6343460083007812\n",
      "training @ epoch 0 .. loss = 1.4369159936904907\n",
      "training @ epoch 0 .. loss = 1.9623527526855469\n",
      "training @ epoch 0 .. loss = 1.6211711168289185\n",
      "training @ epoch 0 .. loss = 1.669540524482727\n",
      "training @ epoch 0 .. loss = 1.7532474994659424\n",
      "training @ epoch 0 .. loss = 1.9399808645248413\n",
      "training @ epoch 0 .. loss = 1.7379982471466064\n",
      "training @ epoch 0 .. loss = 1.4212679862976074\n",
      "training @ epoch 0 .. loss = 1.7289221286773682\n",
      "training @ epoch 0 .. loss = 1.5366946458816528\n",
      "training @ epoch 0 .. loss = 1.4921356439590454\n",
      "training @ epoch 0 .. loss = 1.3446576595306396\n",
      "training @ epoch 0 .. loss = 1.6152856349945068\n",
      "training @ epoch 0 .. loss = 1.5791771411895752\n",
      "training @ epoch 0 .. loss = 1.6681631803512573\n",
      "training @ epoch 0 .. loss = 1.8184260129928589\n",
      "training @ epoch 0 .. loss = 1.5179251432418823\n",
      "training @ epoch 0 .. loss = 1.5509796142578125\n",
      "training @ epoch 0 .. loss = 1.5704269409179688\n",
      "training @ epoch 0 .. loss = 1.5956008434295654\n",
      "training @ epoch 0 .. loss = 1.4948933124542236\n",
      "training @ epoch 0 .. loss = 1.933319330215454\n",
      "training @ epoch 0 .. loss = 1.4329851865768433\n",
      "training @ epoch 0 .. loss = 1.6987926959991455\n",
      "training @ epoch 0 .. loss = 1.7772765159606934\n",
      "training @ epoch 0 .. loss = 1.7005664110183716\n",
      "training @ epoch 0 .. loss = 1.351184606552124\n",
      "training @ epoch 0 .. loss = 2.0289039611816406\n",
      "training @ epoch 0 .. loss = 1.6890400648117065\n",
      "training @ epoch 0 .. loss = 1.681653380393982\n",
      "training @ epoch 0 .. loss = 1.8724392652511597\n",
      "training @ epoch 0 .. loss = 2.3767459392547607\n",
      "training @ epoch 0 .. loss = 1.7644468545913696\n",
      "training @ epoch 0 .. loss = 1.684822678565979\n",
      "training @ epoch 0 .. loss = 1.4366317987442017\n",
      "training @ epoch 0 .. loss = 1.5693676471710205\n",
      "training @ epoch 0 .. loss = 1.8513911962509155\n",
      "training @ epoch 0 .. loss = 1.735514760017395\n",
      "training @ epoch 0 .. loss = 1.4080429077148438\n",
      "training @ epoch 0 .. loss = 1.5658868551254272\n",
      "training @ epoch 0 .. loss = 1.812272548675537\n",
      "training @ epoch 0 .. loss = 1.62162446975708\n",
      "training @ epoch 0 .. loss = 1.6233980655670166\n",
      "training @ epoch 0 .. loss = 1.7600152492523193\n",
      "training @ epoch 0 .. loss = 1.4824570417404175\n",
      "training @ epoch 0 .. loss = 1.8009064197540283\n",
      "training @ epoch 0 .. loss = 1.6240763664245605\n",
      "training @ epoch 0 .. loss = 1.728502869606018\n",
      "training @ epoch 0 .. loss = 1.6504554748535156\n",
      "training @ epoch 0 .. loss = 1.4366495609283447\n",
      "training @ epoch 0 .. loss = 1.5892637968063354\n",
      "training @ epoch 0 .. loss = 1.659019112586975\n",
      "training @ epoch 0 .. loss = 1.7332329750061035\n",
      "training @ epoch 0 .. loss = 1.6981533765792847\n",
      "training @ epoch 0 .. loss = 1.6519992351531982\n",
      "training @ epoch 0 .. loss = 1.3088856935501099\n",
      "training @ epoch 0 .. loss = 1.7472745180130005\n",
      "training @ epoch 0 .. loss = 1.6204861402511597\n",
      "training @ epoch 0 .. loss = 1.8029577732086182\n",
      "training @ epoch 0 .. loss = 1.716200351715088\n",
      "training @ epoch 0 .. loss = 1.5175983905792236\n",
      "training @ epoch 0 .. loss = 1.4140723943710327\n",
      "training @ epoch 0 .. loss = 1.6414216756820679\n",
      "training @ epoch 0 .. loss = 1.8788920640945435\n",
      "training @ epoch 0 .. loss = 1.8384400606155396\n",
      "training @ epoch 0 .. loss = 1.5753366947174072\n",
      "training @ epoch 0 .. loss = 2.001286745071411\n",
      "training @ epoch 0 .. loss = 1.7373032569885254\n",
      "training @ epoch 0 .. loss = 1.6212610006332397\n",
      "training @ epoch 0 .. loss = 1.6957809925079346\n",
      "training @ epoch 0 .. loss = 1.624122142791748\n",
      "training @ epoch 0 .. loss = 1.7236475944519043\n",
      "training @ epoch 0 .. loss = 1.6897438764572144\n",
      "training @ epoch 0 .. loss = 1.7437080144882202\n",
      "training @ epoch 0 .. loss = 1.4782370328903198\n",
      "training @ epoch 0 .. loss = 1.3569378852844238\n",
      "training @ epoch 0 .. loss = 1.737167477607727\n",
      "training @ epoch 0 .. loss = 1.7288780212402344\n",
      "training @ epoch 0 .. loss = 1.9548118114471436\n",
      "training @ epoch 0 .. loss = 1.487067461013794\n",
      "training @ epoch 0 .. loss = 1.5597569942474365\n",
      "training @ epoch 0 .. loss = 1.364261269569397\n",
      "training @ epoch 0 .. loss = 1.6760938167572021\n",
      "training @ epoch 0 .. loss = 1.5425970554351807\n",
      "training @ epoch 0 .. loss = 1.7465062141418457\n",
      "training @ epoch 0 .. loss = 1.395608901977539\n",
      "training @ epoch 0 .. loss = 1.5265618562698364\n",
      "training @ epoch 0 .. loss = 1.6731412410736084\n",
      "training @ epoch 0 .. loss = 1.4905978441238403\n",
      "training @ epoch 0 .. loss = 1.4721028804779053\n",
      "training @ epoch 0 .. loss = 1.5388699769973755\n",
      "training @ epoch 0 .. loss = 1.563820481300354\n",
      "training @ epoch 0 .. loss = 1.5726158618927002\n",
      "training @ epoch 0 .. loss = 1.670277714729309\n",
      "training @ epoch 0 .. loss = 1.9929964542388916\n",
      "training @ epoch 0 .. loss = 1.3099462985992432\n",
      "training @ epoch 0 .. loss = 1.3282243013381958\n",
      "training @ epoch 0 .. loss = 1.7079375982284546\n",
      "training @ epoch 0 .. loss = 1.779753565788269\n",
      "training @ epoch 0 .. loss = 1.9378526210784912\n",
      "training @ epoch 0 .. loss = 1.6877853870391846\n",
      "training @ epoch 0 .. loss = 1.7608141899108887\n",
      "training @ epoch 0 .. loss = 1.514256238937378\n",
      "training @ epoch 0 .. loss = 1.621315598487854\n",
      "training @ epoch 0 .. loss = 1.4086576700210571\n",
      "training @ epoch 0 .. loss = 1.5663261413574219\n",
      "training @ epoch 0 .. loss = 1.637607216835022\n",
      "training @ epoch 0 .. loss = 1.998322606086731\n",
      "training @ epoch 0 .. loss = 1.5759632587432861\n",
      "training @ epoch 0 .. loss = 2.057969331741333\n",
      "training @ epoch 0 .. loss = 1.5329822301864624\n",
      "training @ epoch 0 .. loss = 1.671892762184143\n",
      "training @ epoch 0 .. loss = 1.3800199031829834\n",
      "training @ epoch 0 .. loss = 1.8265079259872437\n",
      "training @ epoch 0 .. loss = 1.6207389831542969\n",
      "training @ epoch 0 .. loss = 1.5729438066482544\n",
      "training @ epoch 0 .. loss = 1.634613275527954\n",
      "training @ epoch 0 .. loss = 1.6200672388076782\n",
      "training @ epoch 0 .. loss = 1.7181230783462524\n",
      "training @ epoch 0 .. loss = 1.7419735193252563\n",
      "training @ epoch 0 .. loss = 1.5001894235610962\n",
      "training @ epoch 0 .. loss = 1.7281005382537842\n",
      "training @ epoch 0 .. loss = 1.5977588891983032\n",
      "training @ epoch 0 .. loss = 1.5658410787582397\n",
      "training @ epoch 0 .. loss = 2.025916814804077\n",
      "training @ epoch 0 .. loss = 1.7485638856887817\n",
      "training @ epoch 0 .. loss = 1.6274248361587524\n",
      "training @ epoch 0 .. loss = 1.619032382965088\n",
      "training @ epoch 0 .. loss = 1.6342655420303345\n",
      "training @ epoch 0 .. loss = 2.0734150409698486\n",
      "training @ epoch 0 .. loss = 1.9398829936981201\n",
      "training @ epoch 0 .. loss = 1.745477557182312\n",
      "training @ epoch 0 .. loss = 1.622236967086792\n",
      "training @ epoch 0 .. loss = 1.5589051246643066\n",
      "training @ epoch 0 .. loss = 1.4648154973983765\n",
      "training @ epoch 0 .. loss = 1.9679970741271973\n",
      "training @ epoch 0 .. loss = 1.8101238012313843\n",
      "training @ epoch 0 .. loss = 1.6456247568130493\n",
      "training @ epoch 0 .. loss = 1.6437324285507202\n",
      "training @ epoch 0 .. loss = 1.8712966442108154\n",
      "training @ epoch 0 .. loss = 1.8094033002853394\n",
      "training @ epoch 0 .. loss = 1.6476424932479858\n",
      "training @ epoch 0 .. loss = 1.8815702199935913\n",
      "training @ epoch 0 .. loss = 1.316735029220581\n",
      "training @ epoch 0 .. loss = 1.649675965309143\n",
      "training @ epoch 0 .. loss = 1.4242948293685913\n",
      "training @ epoch 0 .. loss = 1.5882222652435303\n",
      "training @ epoch 0 .. loss = 1.5099056959152222\n",
      "training @ epoch 0 .. loss = 1.4628208875656128\n",
      "training @ epoch 0 .. loss = 1.626898169517517\n",
      "training @ epoch 0 .. loss = 1.9302747249603271\n",
      "training @ epoch 0 .. loss = 1.7463189363479614\n",
      "training @ epoch 0 .. loss = 1.485537052154541\n",
      "training @ epoch 0 .. loss = 1.687839150428772\n",
      "training @ epoch 0 .. loss = 1.2420384883880615\n",
      "training @ epoch 0 .. loss = 1.5022070407867432\n",
      "training @ epoch 0 .. loss = 1.4937204122543335\n",
      "training @ epoch 0 .. loss = 2.332343101501465\n",
      "training @ epoch 0 .. loss = 1.7292695045471191\n",
      "training @ epoch 0 .. loss = 1.6397309303283691\n",
      "training @ epoch 0 .. loss = 1.4700777530670166\n",
      "training @ epoch 0 .. loss = 1.65414559841156\n",
      "training @ epoch 0 .. loss = 1.5184733867645264\n",
      "training @ epoch 0 .. loss = 1.7387527227401733\n",
      "training @ epoch 0 .. loss = 2.02070689201355\n",
      "training @ epoch 0 .. loss = 1.4224363565444946\n",
      "training @ epoch 0 .. loss = 1.7935101985931396\n",
      "training @ epoch 0 .. loss = 1.874192714691162\n",
      "training @ epoch 0 .. loss = 1.6557526588439941\n",
      "training @ epoch 0 .. loss = 1.7111867666244507\n",
      "training @ epoch 0 .. loss = 1.7936893701553345\n",
      "training @ epoch 0 .. loss = 1.7169743776321411\n",
      "training @ epoch 0 .. loss = 1.615161418914795\n",
      "training @ epoch 0 .. loss = 1.727110505104065\n",
      "training @ epoch 0 .. loss = 1.8280023336410522\n",
      "training @ epoch 0 .. loss = 1.6461595296859741\n",
      "training @ epoch 0 .. loss = 1.8446232080459595\n",
      "training @ epoch 0 .. loss = 1.6466726064682007\n",
      "training @ epoch 0 .. loss = 1.6336675882339478\n",
      "training @ epoch 0 .. loss = 1.8006848096847534\n",
      "training @ epoch 0 .. loss = 1.8372166156768799\n",
      "training @ epoch 0 .. loss = 1.813982367515564\n",
      "training @ epoch 0 .. loss = 1.640763759613037\n",
      "training @ epoch 0 .. loss = 1.5228580236434937\n",
      "training @ epoch 0 .. loss = 1.7532000541687012\n",
      "training @ epoch 0 .. loss = 1.622338891029358\n",
      "training @ epoch 0 .. loss = 1.8402880430221558\n",
      "training @ epoch 0 .. loss = 1.555849313735962\n",
      "training @ epoch 0 .. loss = 1.7400485277175903\n",
      "training @ epoch 0 .. loss = 1.8477606773376465\n",
      "training @ epoch 0 .. loss = 1.4042352437973022\n",
      "training @ epoch 0 .. loss = 1.7981762886047363\n",
      "training @ epoch 0 .. loss = 1.862296462059021\n",
      "training @ epoch 0 .. loss = 1.4606106281280518\n",
      "training @ epoch 0 .. loss = 1.5062224864959717\n",
      "training @ epoch 0 .. loss = 1.490796685218811\n",
      "training @ epoch 0 .. loss = 1.7957638502120972\n",
      "training @ epoch 0 .. loss = 1.9255365133285522\n",
      "training @ epoch 0 .. loss = 1.5086113214492798\n",
      "training @ epoch 0 .. loss = 1.6645281314849854\n",
      "training @ epoch 0 .. loss = 1.581043004989624\n",
      "training @ epoch 0 .. loss = 1.4767889976501465\n",
      "training @ epoch 0 .. loss = 1.5422238111495972\n",
      "training @ epoch 0 .. loss = 1.4096165895462036\n",
      "training @ epoch 0 .. loss = 1.279651165008545\n",
      "training @ epoch 0 .. loss = 1.8200958967208862\n",
      "training @ epoch 0 .. loss = 1.5669901371002197\n",
      "training @ epoch 0 .. loss = 1.8779101371765137\n",
      "training @ epoch 0 .. loss = 1.4219558238983154\n",
      "training @ epoch 0 .. loss = 1.5761440992355347\n",
      "training @ epoch 0 .. loss = 2.162397861480713\n",
      "training @ epoch 0 .. loss = 1.9340550899505615\n",
      "training @ epoch 0 .. loss = 1.4938055276870728\n",
      "training @ epoch 0 .. loss = 1.2366353273391724\n",
      "training @ epoch 0 .. loss = 1.7446134090423584\n",
      "training @ epoch 0 .. loss = 1.6342698335647583\n",
      "training @ epoch 0 .. loss = 1.57511568069458\n",
      "training @ epoch 0 .. loss = 1.5161534547805786\n",
      "training @ epoch 0 .. loss = 1.6532915830612183\n",
      "training @ epoch 0 .. loss = 1.6312220096588135\n",
      "training @ epoch 0 .. loss = 1.7999857664108276\n",
      "training @ epoch 0 .. loss = 1.6575430631637573\n",
      "training @ epoch 0 .. loss = 1.6662657260894775\n",
      "training @ epoch 0 .. loss = 1.6306114196777344\n",
      "training @ epoch 0 .. loss = 1.5561829805374146\n",
      "training @ epoch 0 .. loss = 1.8419321775436401\n",
      "training @ epoch 0 .. loss = 1.429583191871643\n",
      "training @ epoch 0 .. loss = 1.8515969514846802\n",
      "training @ epoch 0 .. loss = 2.1358330249786377\n",
      "training @ epoch 0 .. loss = 1.6113622188568115\n",
      "training @ epoch 0 .. loss = 1.6607939004898071\n",
      "training @ epoch 0 .. loss = 1.5394548177719116\n",
      "training @ epoch 0 .. loss = 1.8079921007156372\n",
      "training @ epoch 0 .. loss = 1.4539629220962524\n",
      "training @ epoch 0 .. loss = 1.5699687004089355\n",
      "training @ epoch 0 .. loss = 1.9222066402435303\n",
      "training @ epoch 0 .. loss = 1.5170655250549316\n",
      "training @ epoch 0 .. loss = 1.8684839010238647\n",
      "training @ epoch 0 .. loss = 1.4710129499435425\n",
      "training @ epoch 0 .. loss = 1.4635179042816162\n",
      "training @ epoch 0 .. loss = 1.7617050409317017\n",
      "training @ epoch 0 .. loss = 1.4884780645370483\n",
      "training @ epoch 0 .. loss = 1.5655925273895264\n",
      "training @ epoch 0 .. loss = 1.746849775314331\n",
      "training @ epoch 0 .. loss = 1.814664602279663\n",
      "training @ epoch 0 .. loss = 1.4688128232955933\n",
      "training @ epoch 0 .. loss = 1.8460700511932373\n",
      "training @ epoch 0 .. loss = 1.4405750036239624\n",
      "training @ epoch 0 .. loss = 1.7527364492416382\n",
      "training @ epoch 0 .. loss = 1.7498737573623657\n",
      "training @ epoch 0 .. loss = 1.576755404472351\n",
      "training @ epoch 0 .. loss = 1.3693175315856934\n",
      "training @ epoch 0 .. loss = 1.5013909339904785\n",
      "training @ epoch 0 .. loss = 1.5316178798675537\n",
      "training @ epoch 0 .. loss = 1.2513922452926636\n",
      "training @ epoch 0 .. loss = 1.8080135583877563\n",
      "training @ epoch 0 .. loss = 1.6478588581085205\n",
      "training @ epoch 0 .. loss = 1.416042685508728\n",
      "training @ epoch 0 .. loss = 1.9771721363067627\n",
      "training @ epoch 0 .. loss = 1.4761550426483154\n",
      "training @ epoch 0 .. loss = 1.037235140800476\n",
      "training @ epoch 0 .. loss = 1.9651132822036743\n",
      "training @ epoch 0 .. loss = 1.5911309719085693\n",
      "training @ epoch 0 .. loss = 1.433824896812439\n",
      "training @ epoch 0 .. loss = 1.5877429246902466\n",
      "training @ epoch 0 .. loss = 2.012465000152588\n",
      "training @ epoch 0 .. loss = 1.50330650806427\n",
      "training @ epoch 0 .. loss = 1.6008238792419434\n",
      "training @ epoch 0 .. loss = 1.987066388130188\n",
      "training @ epoch 0 .. loss = 1.5997428894042969\n",
      "training @ epoch 0 .. loss = 1.3961818218231201\n",
      "training @ epoch 0 .. loss = 1.4674108028411865\n",
      "training @ epoch 0 .. loss = 1.5229814052581787\n",
      "training @ epoch 0 .. loss = 1.6197375059127808\n",
      "training @ epoch 0 .. loss = 1.9264202117919922\n",
      "training @ epoch 0 .. loss = 1.8973337411880493\n",
      "training @ epoch 0 .. loss = 1.570776343345642\n",
      "training @ epoch 0 .. loss = 1.3774340152740479\n",
      "training @ epoch 0 .. loss = 1.65064537525177\n",
      "training @ epoch 0 .. loss = 1.8573964834213257\n",
      "training @ epoch 0 .. loss = 1.5558050870895386\n",
      "training @ epoch 0 .. loss = 1.940595269203186\n",
      "training @ epoch 0 .. loss = 1.641493320465088\n",
      "training @ epoch 0 .. loss = 1.6298660039901733\n",
      "training @ epoch 0 .. loss = 1.6474889516830444\n",
      "training @ epoch 0 .. loss = 1.9035247564315796\n",
      "training @ epoch 0 .. loss = 1.4292454719543457\n",
      "training @ epoch 0 .. loss = 1.463982105255127\n",
      "training @ epoch 0 .. loss = 1.6636245250701904\n",
      "training @ epoch 0 .. loss = 1.994408130645752\n",
      "training @ epoch 0 .. loss = 1.447601318359375\n",
      "training @ epoch 0 .. loss = 1.5142501592636108\n",
      "training @ epoch 0 .. loss = 2.0057199001312256\n",
      "training @ epoch 0 .. loss = 1.6733042001724243\n",
      "training @ epoch 0 .. loss = 1.4106731414794922\n",
      "training @ epoch 0 .. loss = 1.9469013214111328\n",
      "training @ epoch 0 .. loss = 1.4501006603240967\n",
      "training @ epoch 0 .. loss = 1.6846470832824707\n",
      "training @ epoch 0 .. loss = 1.4087961912155151\n",
      "training @ epoch 0 .. loss = 1.7705113887786865\n",
      "training @ epoch 0 .. loss = 1.5163136720657349\n",
      "training @ epoch 0 .. loss = 1.5423518419265747\n",
      "training @ epoch 0 .. loss = 1.5882352590560913\n",
      "training @ epoch 0 .. loss = 1.7231662273406982\n",
      "training @ epoch 0 .. loss = 1.6085354089736938\n",
      "training @ epoch 0 .. loss = 1.6414793729782104\n",
      "training @ epoch 0 .. loss = 1.480492353439331\n",
      "training @ epoch 0 .. loss = 1.4682972431182861\n",
      "training @ epoch 0 .. loss = 1.599609375\n",
      "training @ epoch 0 .. loss = 1.7632641792297363\n",
      "training @ epoch 0 .. loss = 1.450685739517212\n",
      "training @ epoch 0 .. loss = 1.5094882249832153\n",
      "training @ epoch 0 .. loss = 1.559772253036499\n",
      "training @ epoch 0 .. loss = 1.410521149635315\n",
      "training @ epoch 0 .. loss = 2.051271438598633\n",
      "training @ epoch 0 .. loss = 1.3580251932144165\n",
      "training @ epoch 0 .. loss = 1.2584497928619385\n",
      "training @ epoch 0 .. loss = 2.0979113578796387\n",
      "training @ epoch 0 .. loss = 1.346742033958435\n",
      "training @ epoch 0 .. loss = 1.6065250635147095\n",
      "training @ epoch 0 .. loss = 1.8789916038513184\n",
      "training @ epoch 0 .. loss = 1.553538203239441\n",
      "training @ epoch 0 .. loss = 1.7385166883468628\n",
      "training @ epoch 0 .. loss = 1.623266577720642\n",
      "training @ epoch 0 .. loss = 1.911859393119812\n",
      "training @ epoch 0 .. loss = 1.5624498128890991\n",
      "training @ epoch 0 .. loss = 1.5670924186706543\n",
      "training @ epoch 0 .. loss = 1.340569257736206\n",
      "training @ epoch 0 .. loss = 1.6690280437469482\n",
      "training @ epoch 0 .. loss = 1.3632943630218506\n",
      "training @ epoch 0 .. loss = 1.5908817052841187\n",
      "training @ epoch 0 .. loss = 1.5702869892120361\n",
      "training @ epoch 0 .. loss = 1.6930217742919922\n",
      "training @ epoch 0 .. loss = 1.515113353729248\n",
      "training @ epoch 0 .. loss = 1.4965424537658691\n",
      "training @ epoch 0 .. loss = 1.4497028589248657\n",
      "training @ epoch 0 .. loss = 2.1224684715270996\n",
      "training @ epoch 0 .. loss = 1.7230031490325928\n",
      "training @ epoch 0 .. loss = 1.841746211051941\n",
      "training @ epoch 0 .. loss = 1.7168182134628296\n",
      "training @ epoch 0 .. loss = 1.6265150308609009\n",
      "training @ epoch 0 .. loss = 1.5150054693222046\n",
      "training @ epoch 0 .. loss = 1.4751728773117065\n",
      "training @ epoch 0 .. loss = 1.5859551429748535\n",
      "training @ epoch 0 .. loss = 1.8165042400360107\n",
      "training @ epoch 0 .. loss = 1.964476227760315\n",
      "training @ epoch 0 .. loss = 1.7612391710281372\n",
      "training @ epoch 0 .. loss = 1.398719072341919\n",
      "training @ epoch 0 .. loss = 1.5564746856689453\n",
      "training @ epoch 0 .. loss = 1.4426093101501465\n",
      "training @ epoch 0 .. loss = 1.6824545860290527\n",
      "training @ epoch 0 .. loss = 1.3052290678024292\n",
      "training @ epoch 0 .. loss = 1.5769575834274292\n",
      "training @ epoch 0 .. loss = 1.5182853937149048\n",
      "training @ epoch 0 .. loss = 1.8440170288085938\n",
      "training @ epoch 0 .. loss = 1.6281534433364868\n",
      "training @ epoch 0 .. loss = 1.6672083139419556\n",
      "training @ epoch 0 .. loss = 1.1963918209075928\n",
      "training @ epoch 0 .. loss = 1.7930275201797485\n",
      "training @ epoch 0 .. loss = 1.8908933401107788\n",
      "training @ epoch 0 .. loss = 1.4282554388046265\n",
      "training @ epoch 0 .. loss = 1.7026844024658203\n",
      "training @ epoch 0 .. loss = 1.7086279392242432\n",
      "training @ epoch 0 .. loss = 1.7199891805648804\n",
      "training @ epoch 0 .. loss = 1.8052834272384644\n",
      "training @ epoch 0 .. loss = 1.4945297241210938\n",
      "training @ epoch 0 .. loss = 1.7722889184951782\n",
      "training @ epoch 0 .. loss = 1.6796320676803589\n",
      "training @ epoch 0 .. loss = 1.5708931684494019\n",
      "training @ epoch 0 .. loss = 1.7090660333633423\n",
      "training @ epoch 0 .. loss = 1.4807194471359253\n",
      "training @ epoch 0 .. loss = 1.8367440700531006\n",
      "training @ epoch 0 .. loss = 1.7316170930862427\n",
      "training @ epoch 0 .. loss = 1.4458800554275513\n",
      "training @ epoch 0 .. loss = 1.6700894832611084\n",
      "training @ epoch 0 .. loss = 1.4368550777435303\n",
      "training @ epoch 0 .. loss = 1.9378215074539185\n",
      "training @ epoch 0 .. loss = 1.4496139287948608\n",
      "training @ epoch 0 .. loss = 1.6601699590682983\n",
      "training @ epoch 0 .. loss = 1.550552248954773\n",
      "training @ epoch 0 .. loss = 1.794134497642517\n",
      "training @ epoch 0 .. loss = 1.367482304573059\n",
      "training @ epoch 0 .. loss = 1.896172046661377\n",
      "training @ epoch 0 .. loss = 1.8417872190475464\n",
      "training @ epoch 0 .. loss = 1.6434794664382935\n",
      "training @ epoch 0 .. loss = 1.993764042854309\n",
      "training @ epoch 0 .. loss = 1.470823884010315\n",
      "training @ epoch 0 .. loss = 1.806315302848816\n",
      "training @ epoch 0 .. loss = 1.7040728330612183\n",
      "training @ epoch 0 .. loss = 1.3928834199905396\n",
      "training @ epoch 0 .. loss = 1.6486961841583252\n",
      "training @ epoch 0 .. loss = 1.8144620656967163\n",
      "training @ epoch 0 .. loss = 1.6954916715621948\n",
      "training @ epoch 0 .. loss = 1.5978730916976929\n",
      "training @ epoch 0 .. loss = 1.8305950164794922\n",
      "training @ epoch 0 .. loss = 1.498810887336731\n",
      "training @ epoch 0 .. loss = 1.6684149503707886\n",
      "training @ epoch 0 .. loss = 1.7799617052078247\n",
      "training @ epoch 0 .. loss = 1.577772855758667\n",
      "training @ epoch 0 .. loss = 1.4695411920547485\n",
      "training @ epoch 0 .. loss = 1.8621746301651\n",
      "training @ epoch 0 .. loss = 1.492390513420105\n",
      "training @ epoch 0 .. loss = 1.6591464281082153\n",
      "training @ epoch 0 .. loss = 1.6497457027435303\n",
      "training @ epoch 0 .. loss = 1.5766451358795166\n",
      "training @ epoch 0 .. loss = 1.7072910070419312\n",
      "training @ epoch 0 .. loss = 2.218304395675659\n",
      "training @ epoch 0 .. loss = 1.6093597412109375\n",
      "training @ epoch 0 .. loss = 1.5398749113082886\n",
      "training @ epoch 0 .. loss = 1.7773362398147583\n",
      "training @ epoch 0 .. loss = 1.4659258127212524\n",
      "training @ epoch 0 .. loss = 1.68543541431427\n",
      "training @ epoch 0 .. loss = 1.6203455924987793\n",
      "training @ epoch 0 .. loss = 1.5833947658538818\n",
      "training @ epoch 0 .. loss = 1.6545296907424927\n",
      "training @ epoch 0 .. loss = 1.559863805770874\n",
      "training @ epoch 0 .. loss = 1.677496075630188\n",
      "training @ epoch 0 .. loss = 1.630344033241272\n",
      "training @ epoch 0 .. loss = 1.7184809446334839\n",
      "training @ epoch 0 .. loss = 1.6919891834259033\n",
      "training @ epoch 0 .. loss = 1.4823857545852661\n",
      "training @ epoch 0 .. loss = 1.6363511085510254\n",
      "training @ epoch 0 .. loss = 1.513708233833313\n",
      "training @ epoch 0 .. loss = 1.6849749088287354\n",
      "training @ epoch 0 .. loss = 1.943811297416687\n",
      "training @ epoch 0 .. loss = 1.5613160133361816\n",
      "training @ epoch 0 .. loss = 1.8626201152801514\n",
      "training @ epoch 0 .. loss = 1.5695762634277344\n",
      "training @ epoch 0 .. loss = 1.7678393125534058\n",
      "training @ epoch 0 .. loss = 1.541087031364441\n",
      "training @ epoch 0 .. loss = 1.5973867177963257\n",
      "training @ epoch 0 .. loss = 1.9848276376724243\n",
      "training @ epoch 0 .. loss = 1.598987102508545\n",
      "training @ epoch 0 .. loss = 1.2988953590393066\n",
      "training @ epoch 0 .. loss = 1.6238987445831299\n",
      "training @ epoch 0 .. loss = 1.6916335821151733\n",
      "training @ epoch 0 .. loss = 1.7064478397369385\n",
      "training @ epoch 0 .. loss = 1.8973134756088257\n",
      "training @ epoch 0 .. loss = 1.5757709741592407\n",
      "training @ epoch 0 .. loss = 1.5089012384414673\n",
      "training @ epoch 0 .. loss = 1.5716708898544312\n",
      "training @ epoch 0 .. loss = 1.9982223510742188\n",
      "training @ epoch 0 .. loss = 1.6846835613250732\n",
      "training @ epoch 0 .. loss = 1.838982105255127\n",
      "training @ epoch 0 .. loss = 1.6406657695770264\n",
      "training @ epoch 0 .. loss = 2.1001627445220947\n",
      "training @ epoch 0 .. loss = 1.5315492153167725\n",
      "training @ epoch 0 .. loss = 1.674233317375183\n",
      "training @ epoch 0 .. loss = 1.6076819896697998\n",
      "training @ epoch 0 .. loss = 1.8506535291671753\n",
      "training @ epoch 0 .. loss = 1.892764687538147\n",
      "training @ epoch 0 .. loss = 1.5649819374084473\n",
      "training @ epoch 0 .. loss = 1.4133280515670776\n",
      "training @ epoch 0 .. loss = 1.6774431467056274\n",
      "training @ epoch 0 .. loss = 1.5332130193710327\n",
      "training @ epoch 0 .. loss = 1.476487636566162\n",
      "training @ epoch 0 .. loss = 1.5094512701034546\n",
      "training @ epoch 0 .. loss = 1.5525046586990356\n",
      "training @ epoch 0 .. loss = 1.9778823852539062\n",
      "training @ epoch 0 .. loss = 1.4330562353134155\n",
      "training @ epoch 0 .. loss = 1.334460973739624\n",
      "training @ epoch 0 .. loss = 1.9576205015182495\n",
      "training @ epoch 0 .. loss = 1.5560067892074585\n",
      "training @ epoch 0 .. loss = 1.822583556175232\n",
      "training @ epoch 0 .. loss = 1.4404622316360474\n",
      "training @ epoch 0 .. loss = 1.5830622911453247\n",
      "training @ epoch 0 .. loss = 1.7507492303848267\n",
      "training @ epoch 0 .. loss = 1.4168339967727661\n",
      "training @ epoch 0 .. loss = 1.781312108039856\n",
      "training @ epoch 0 .. loss = 1.834959864616394\n",
      "training @ epoch 0 .. loss = 1.2231687307357788\n",
      "training @ epoch 0 .. loss = 1.5766626596450806\n",
      "training @ epoch 0 .. loss = 1.9185335636138916\n",
      "training @ epoch 0 .. loss = 2.2283079624176025\n",
      "training @ epoch 0 .. loss = 1.8726868629455566\n",
      "training @ epoch 0 .. loss = 1.7320805788040161\n",
      "training @ epoch 0 .. loss = 1.7884547710418701\n",
      "training @ epoch 0 .. loss = 1.6766583919525146\n",
      "training @ epoch 0 .. loss = 1.7419488430023193\n",
      "training @ epoch 0 .. loss = 1.435052752494812\n",
      "training @ epoch 0 .. loss = 1.5623525381088257\n",
      "training @ epoch 0 .. loss = 2.0773770809173584\n",
      "training @ epoch 0 .. loss = 1.3890129327774048\n",
      "training @ epoch 0 .. loss = 1.7527482509613037\n",
      "training @ epoch 0 .. loss = 1.4133079051971436\n",
      "training @ epoch 0 .. loss = 1.397268533706665\n",
      "training @ epoch 0 .. loss = 2.0199272632598877\n",
      "training @ epoch 0 .. loss = 1.8044968843460083\n",
      "training @ epoch 0 .. loss = 1.5343430042266846\n",
      "training @ epoch 0 .. loss = 1.7254704236984253\n",
      "training @ epoch 0 .. loss = 1.3553643226623535\n",
      "training @ epoch 0 .. loss = 1.7604343891143799\n",
      "training @ epoch 0 .. loss = 1.8587672710418701\n",
      "training @ epoch 0 .. loss = 1.343451976776123\n",
      "training @ epoch 0 .. loss = 1.6511300802230835\n",
      "training @ epoch 0 .. loss = 1.611879825592041\n",
      "training @ epoch 0 .. loss = 1.6508618593215942\n",
      "training @ epoch 0 .. loss = 2.0472054481506348\n",
      "training @ epoch 0 .. loss = 2.011369228363037\n",
      "training @ epoch 0 .. loss = 1.5551106929779053\n",
      "training @ epoch 0 .. loss = 1.6598305702209473\n",
      "training @ epoch 0 .. loss = 1.550704836845398\n",
      "training @ epoch 0 .. loss = 1.770922064781189\n",
      "training @ epoch 0 .. loss = 1.846861720085144\n",
      "training @ epoch 0 .. loss = 1.5002245903015137\n",
      "training @ epoch 0 .. loss = 1.6661720275878906\n",
      "training @ epoch 0 .. loss = 1.4736511707305908\n",
      "training @ epoch 0 .. loss = 1.6132711172103882\n",
      "training @ epoch 0 .. loss = 1.470408320426941\n",
      "training @ epoch 0 .. loss = 1.7727711200714111\n",
      "training @ epoch 0 .. loss = 1.3416210412979126\n",
      "training @ epoch 0 .. loss = 1.5733357667922974\n",
      "training @ epoch 0 .. loss = 1.3725731372833252\n",
      "training @ epoch 0 .. loss = 1.7244383096694946\n",
      "training @ epoch 0 .. loss = 1.5699565410614014\n",
      "training @ epoch 0 .. loss = 1.5890871286392212\n",
      "training @ epoch 0 .. loss = 1.3254474401474\n",
      "training @ epoch 0 .. loss = 1.6769965887069702\n",
      "training @ epoch 0 .. loss = 1.5436570644378662\n",
      "training @ epoch 0 .. loss = 1.5447821617126465\n",
      "training @ epoch 0 .. loss = 1.5256398916244507\n",
      "training @ epoch 0 .. loss = 1.4172784090042114\n",
      "training @ epoch 0 .. loss = 1.452054500579834\n",
      "training @ epoch 0 .. loss = 1.640511393547058\n",
      "training @ epoch 0 .. loss = 1.5851348638534546\n",
      "training @ epoch 0 .. loss = 1.8067853450775146\n",
      "training @ epoch 0 .. loss = 1.5521787405014038\n",
      "training @ epoch 0 .. loss = 1.7032463550567627\n",
      "training @ epoch 0 .. loss = 1.8106642961502075\n",
      "training @ epoch 0 .. loss = 1.375018835067749\n",
      "training @ epoch 0 .. loss = 1.9114766120910645\n",
      "training @ epoch 0 .. loss = 1.7952874898910522\n",
      "training @ epoch 0 .. loss = 1.6847102642059326\n",
      "training @ epoch 0 .. loss = 1.5535757541656494\n",
      "training @ epoch 0 .. loss = 1.8052159547805786\n",
      "training @ epoch 0 .. loss = 1.8346716165542603\n",
      "training @ epoch 0 .. loss = 1.3942286968231201\n",
      "training @ epoch 0 .. loss = 1.2429317235946655\n",
      "training @ epoch 0 .. loss = 1.6915849447250366\n",
      "training @ epoch 0 .. loss = 2.120659351348877\n",
      "training @ epoch 0 .. loss = 1.4922940731048584\n",
      "training @ epoch 0 .. loss = 1.5153247117996216\n",
      "training @ epoch 0 .. loss = 1.7191283702850342\n",
      "training @ epoch 0 .. loss = 1.706831455230713\n",
      "training @ epoch 0 .. loss = 1.2348453998565674\n",
      "training @ epoch 0 .. loss = 2.2617456912994385\n",
      "training @ epoch 0 .. loss = 1.4763922691345215\n",
      "training @ epoch 0 .. loss = 1.492458462715149\n",
      "training @ epoch 0 .. loss = 1.5567256212234497\n",
      "training @ epoch 0 .. loss = 1.4086755514144897\n",
      "training @ epoch 0 .. loss = 1.5362135171890259\n",
      "training @ epoch 0 .. loss = 1.5984272956848145\n",
      "training @ epoch 0 .. loss = 1.7074373960494995\n",
      "training @ epoch 0 .. loss = 1.7062093019485474\n",
      "training @ epoch 0 .. loss = 1.8565311431884766\n",
      "training @ epoch 0 .. loss = 1.9955503940582275\n",
      "training @ epoch 0 .. loss = 1.4409911632537842\n",
      "training @ epoch 0 .. loss = 1.787277102470398\n",
      "training @ epoch 0 .. loss = 1.5049883127212524\n",
      "training @ epoch 0 .. loss = 1.7509506940841675\n",
      "training @ epoch 0 .. loss = 2.1761631965637207\n",
      "training @ epoch 0 .. loss = 1.7896502017974854\n",
      "training @ epoch 0 .. loss = 1.8082627058029175\n",
      "training @ epoch 0 .. loss = 1.8049155473709106\n",
      "training @ epoch 0 .. loss = 1.5430972576141357\n",
      "training @ epoch 0 .. loss = 1.4855862855911255\n",
      "training @ epoch 0 .. loss = 1.5387701988220215\n",
      "training @ epoch 0 .. loss = 1.3972163200378418\n",
      "training @ epoch 0 .. loss = 1.7350258827209473\n",
      "training @ epoch 0 .. loss = 1.726347804069519\n",
      "training @ epoch 0 .. loss = 1.4275221824645996\n",
      "training @ epoch 0 .. loss = 1.5374696254730225\n",
      "training @ epoch 0 .. loss = 1.5367900133132935\n",
      "training @ epoch 0 .. loss = 1.7798761129379272\n",
      "training @ epoch 0 .. loss = 1.3454797267913818\n",
      "training @ epoch 0 .. loss = 1.5561202764511108\n",
      "training @ epoch 0 .. loss = 1.491655707359314\n",
      "training @ epoch 0 .. loss = 1.4420899152755737\n",
      "training @ epoch 0 .. loss = 1.7860866785049438\n",
      "training @ epoch 0 .. loss = 1.562227725982666\n",
      "training @ epoch 0 .. loss = 1.762819766998291\n",
      "training @ epoch 0 .. loss = 1.2139126062393188\n",
      "training @ epoch 0 .. loss = 1.4938050508499146\n",
      "training @ epoch 0 .. loss = 1.3888007402420044\n",
      "training @ epoch 0 .. loss = 1.9414985179901123\n",
      "training @ epoch 0 .. loss = 1.5240260362625122\n",
      "training @ epoch 0 .. loss = 1.6609172821044922\n",
      "training @ epoch 0 .. loss = 1.5591458082199097\n",
      "training @ epoch 0 .. loss = 1.3908635377883911\n",
      "training @ epoch 0 .. loss = 1.373258352279663\n",
      "training @ epoch 0 .. loss = 1.0246949195861816\n",
      "training @ epoch 0 .. loss = 1.5580207109451294\n",
      "training @ epoch 0 .. loss = 1.512024998664856\n",
      "training @ epoch 0 .. loss = 1.9712607860565186\n",
      "training @ epoch 0 .. loss = 1.3070341348648071\n",
      "training @ epoch 0 .. loss = 1.7749974727630615\n",
      "training @ epoch 0 .. loss = 1.5896508693695068\n",
      "training @ epoch 0 .. loss = 1.6614460945129395\n",
      "training @ epoch 0 .. loss = 1.5694223642349243\n",
      "training @ epoch 0 .. loss = 1.30963933467865\n",
      "training @ epoch 0 .. loss = 1.0173137187957764\n",
      "training @ epoch 0 .. loss = 1.594943881034851\n",
      "training @ epoch 0 .. loss = 1.5968782901763916\n",
      "training @ epoch 0 .. loss = 1.6122161149978638\n",
      "training @ epoch 0 .. loss = 1.8769326210021973\n",
      "training @ epoch 0 .. loss = 1.3078266382217407\n",
      "training @ epoch 0 .. loss = 2.15315318107605\n",
      "training @ epoch 0 .. loss = 2.0736680030822754\n",
      "training @ epoch 0 .. loss = 1.244242787361145\n",
      "training @ epoch 0 .. loss = 1.5028785467147827\n",
      "training @ epoch 0 .. loss = 1.1953856945037842\n",
      "training @ epoch 0 .. loss = 1.5866379737854004\n",
      "training @ epoch 0 .. loss = 1.371559977531433\n",
      "training @ epoch 0 .. loss = 1.5412565469741821\n",
      "training @ epoch 0 .. loss = 1.6439776420593262\n",
      "training @ epoch 0 .. loss = 1.8811696767807007\n",
      "training @ epoch 0 .. loss = 1.6129924058914185\n",
      "training @ epoch 0 .. loss = 1.2016202211380005\n",
      "training @ epoch 0 .. loss = 1.571496605873108\n",
      "training @ epoch 0 .. loss = 1.8639588356018066\n",
      "training @ epoch 0 .. loss = 1.814444899559021\n",
      "training @ epoch 0 .. loss = 1.4944666624069214\n",
      "training @ epoch 0 .. loss = 1.4397168159484863\n",
      "training @ epoch 0 .. loss = 1.1846728324890137\n",
      "training @ epoch 0 .. loss = 1.410430908203125\n",
      "training @ epoch 0 .. loss = 1.8489638566970825\n",
      "training @ epoch 0 .. loss = 1.5029253959655762\n",
      "training @ epoch 0 .. loss = 1.7067914009094238\n",
      "training @ epoch 0 .. loss = 1.4202749729156494\n",
      "training @ epoch 0 .. loss = 1.7507661581039429\n",
      "training @ epoch 0 .. loss = 1.6894214153289795\n",
      "training @ epoch 0 .. loss = 1.3701754808425903\n",
      "training @ epoch 0 .. loss = 1.451745867729187\n",
      "training @ epoch 0 .. loss = 1.4883264303207397\n",
      "training @ epoch 0 .. loss = 1.7129671573638916\n",
      "training @ epoch 0 .. loss = 1.5806820392608643\n",
      "training @ epoch 0 .. loss = 1.8396426439285278\n",
      "training @ epoch 0 .. loss = 1.3104039430618286\n",
      "training @ epoch 0 .. loss = 2.1725451946258545\n",
      "training @ epoch 0 .. loss = 1.6463732719421387\n",
      "training @ epoch 0 .. loss = 1.8463571071624756\n",
      "training @ epoch 0 .. loss = 1.8223562240600586\n",
      "validation loss = 2.446542263031006\n",
      "validation loss = 2.035560369491577\n",
      "validation loss = 1.9690676927566528\n",
      "validation loss = 1.8596259355545044\n",
      "validation loss = 1.92172372341156\n",
      "validation loss = 1.930063247680664\n",
      "validation loss = 1.788666844367981\n",
      "validation loss = 1.716558814048767\n",
      "validation loss = 2.0895142555236816\n",
      "validation loss = 1.833166241645813\n",
      "validation loss = 2.035356044769287\n",
      "validation loss = 2.097639560699463\n",
      "validation loss = 2.1370058059692383\n",
      "validation loss = 1.7740864753723145\n",
      "validation loss = 2.049394130706787\n",
      "validation loss = 2.0508923530578613\n",
      "validation loss = 1.916909098625183\n",
      "validation loss = 1.585795521736145\n",
      "validation loss = 1.680105447769165\n",
      "validation loss = 2.1402716636657715\n",
      "validation loss = 2.023777961730957\n",
      "validation loss = 1.9602383375167847\n",
      "validation loss = 1.6049857139587402\n",
      "validation loss = 2.034487724304199\n",
      "validation loss = 2.3984806537628174\n",
      "validation loss = 2.0153720378875732\n",
      "validation loss = 2.1987524032592773\n",
      "validation loss = 1.8573155403137207\n",
      "validation loss = 1.9945063591003418\n",
      "validation loss = 1.7964513301849365\n",
      "validation loss = 2.7143921852111816\n",
      "validation loss = 1.8408375978469849\n",
      "validation loss = 2.0031814575195312\n",
      "validation loss = 1.5753400325775146\n",
      "validation loss = 1.8199760913848877\n",
      "validation loss = 1.5430278778076172\n",
      "validation loss = 1.9673092365264893\n",
      "validation loss = 2.338636875152588\n",
      "validation loss = 2.1771576404571533\n",
      "validation loss = 1.7809633016586304\n",
      "validation loss = 2.0961527824401855\n",
      "validation loss = 2.010300874710083\n",
      "validation loss = 2.3287768363952637\n",
      "validation loss = 1.9236540794372559\n",
      "validation loss = 1.7561694383621216\n",
      "validation loss = 1.915116786956787\n",
      "validation loss = 1.7186321020126343\n",
      "validation loss = 1.6611671447753906\n",
      "validation loss = 1.9226797819137573\n",
      "validation loss = 2.145838499069214\n",
      "validation loss = 1.9441694021224976\n",
      "validation loss = 1.969915509223938\n",
      "validation loss = 1.7496464252471924\n",
      "validation loss = 2.1211016178131104\n",
      "validation loss = 1.7451941967010498\n",
      "validation loss = 1.7405592203140259\n",
      "validation loss = 2.448208808898926\n",
      "validation loss = 1.7880843877792358\n",
      "validation loss = 2.2640790939331055\n",
      "validation loss = 2.444622278213501\n",
      "validation loss = 2.004814624786377\n",
      "validation loss = 2.2842140197753906\n",
      "validation loss = 1.60008704662323\n",
      "validation loss = 1.88027024269104\n",
      "validation loss = 2.313279151916504\n",
      "validation loss = 1.9386553764343262\n",
      "validation loss = 2.026472568511963\n",
      "validation loss = 1.9406243562698364\n",
      "validation loss = 1.8522292375564575\n",
      "validation loss = 1.6912391185760498\n",
      "validation loss = 2.2648627758026123\n",
      "validation loss = 2.0281667709350586\n",
      "validation loss = 2.201402425765991\n",
      "validation loss = 2.0025153160095215\n",
      "validation loss = 1.7609983682632446\n",
      "validation loss = 2.057715892791748\n",
      "validation loss = 1.9396233558654785\n",
      "validation loss = 1.6963539123535156\n",
      "validation loss = 1.7126507759094238\n",
      "validation loss = 1.916527509689331\n",
      "validation loss = 1.9881327152252197\n",
      "validation loss = 2.0020689964294434\n",
      "validation loss = 2.166072368621826\n",
      "validation loss = 2.022575616836548\n",
      "validation loss = 2.0319902896881104\n",
      "validation loss = 1.6003919839859009\n",
      "validation loss = 2.1436917781829834\n",
      "validation loss = 1.9960764646530151\n",
      "validation loss = 1.9881082773208618\n",
      "validation loss = 1.8847272396087646\n",
      "validation loss = 1.691192865371704\n",
      "validation loss = 2.23266339302063\n",
      "validation loss = 2.0815534591674805\n",
      "validation loss = 1.8343164920806885\n",
      "validation loss = 2.2896575927734375\n",
      "validation loss = 1.990484356880188\n",
      "validation loss = 1.7709017992019653\n",
      "validation loss = 1.7502447366714478\n",
      "validation loss = 2.546048164367676\n",
      "validation loss = 1.789879560470581\n",
      "validation loss = 1.8460136651992798\n",
      "validation loss = 1.8417130708694458\n",
      "validation loss = 1.7322343587875366\n",
      "validation loss = 1.5837061405181885\n",
      "validation loss = 2.696390390396118\n",
      "validation loss = 2.6481127738952637\n",
      "validation loss = 1.7249202728271484\n",
      "validation loss = 2.2658133506774902\n",
      "validation loss = 1.9680287837982178\n",
      "validation loss = 1.7943836450576782\n",
      "validation loss = 2.335930347442627\n",
      "validation loss = 1.8492025136947632\n",
      "validation loss = 1.760444164276123\n",
      "validation loss = 2.188755750656128\n",
      "validation loss = 2.1696555614471436\n",
      "validation loss = 1.8207643032073975\n",
      "validation loss = 1.9803768396377563\n",
      "validation loss = 1.8163139820098877\n",
      "validation loss = 2.2410900592803955\n",
      "validation loss = 1.5711803436279297\n",
      "validation loss = 1.9680371284484863\n",
      "validation loss = 1.9255505800247192\n",
      "validation loss = 2.0691163539886475\n",
      "validation loss = 2.140360116958618\n",
      "validation loss = 1.6963404417037964\n",
      "validation loss = 2.383659601211548\n",
      "validation loss = 2.1187803745269775\n",
      "validation loss = 2.352106809616089\n",
      "validation loss = 2.405116319656372\n",
      "validation loss = 2.0574307441711426\n",
      "validation loss = 2.1678097248077393\n",
      "validation loss = 2.209594249725342\n",
      "validation loss = 2.2401673793792725\n",
      "validation loss = 2.038450241088867\n",
      "validation loss = 2.0169835090637207\n",
      "validation loss = 1.789516568183899\n",
      "validation loss = 1.9234957695007324\n",
      "validation loss = 2.380866050720215\n",
      "validation loss = 1.9832960367202759\n",
      "validation loss = 2.1443963050842285\n",
      "validation loss = 1.7874577045440674\n",
      "validation loss = 1.9603855609893799\n",
      "validation loss = 1.9734365940093994\n",
      "validation loss = 1.9298559427261353\n",
      "validation loss = 2.1427762508392334\n",
      "validation loss = 1.8868138790130615\n",
      "validation loss = 2.383593797683716\n",
      "validation loss = 1.769428014755249\n",
      "validation loss = 2.565526247024536\n",
      "validation loss = 1.8660309314727783\n",
      "validation loss = 2.6143081188201904\n",
      "validation loss = 2.129059314727783\n",
      "validation loss = 1.7606291770935059\n",
      "validation loss = 2.5288918018341064\n",
      "validation loss = 2.5643386840820312\n",
      "validation loss = 2.192023277282715\n",
      "validation loss = 1.9172019958496094\n",
      "validation loss = 1.8961323499679565\n",
      "validation loss = 1.9985991716384888\n",
      "validation loss = 1.6524922847747803\n",
      "validation loss = 1.8656567335128784\n",
      "validation loss = 2.165160655975342\n",
      "validation loss = 1.994383454322815\n",
      "validation loss = 1.8886005878448486\n",
      "validation loss = 1.941681146621704\n",
      "validation loss = 1.7094213962554932\n",
      "validation loss = 2.426079750061035\n",
      "validation loss = 2.6307575702667236\n",
      "validation loss = 2.0724573135375977\n",
      "validation loss = 1.8055171966552734\n",
      "validation loss = 1.7665408849716187\n",
      "validation loss = 2.135070562362671\n",
      "validation loss = 1.8306257724761963\n",
      "validation loss = 1.402753233909607\n",
      "validation loss = 1.9445455074310303\n",
      "validation loss = 2.0301244258880615\n",
      "validation loss = 2.285580635070801\n",
      "validation loss = 1.753424048423767\n",
      "validation loss = 1.419487714767456\n",
      "validation loss = 2.3400368690490723\n",
      "validation loss = 2.1654233932495117\n",
      "validation loss = 1.3698822259902954\n",
      "validation loss = 1.8866896629333496\n",
      "validation loss = 2.233365297317505\n",
      "validation loss = 1.8478025197982788\n",
      "validation loss = 2.0547919273376465\n",
      "validation loss = 1.326066255569458\n",
      "validation loss = 1.9608324766159058\n",
      "validation loss = 2.4825854301452637\n",
      "validation loss = 2.0688652992248535\n",
      "validation loss = 2.0292816162109375\n",
      "validation loss = 1.675650954246521\n",
      "validation loss = 1.7268502712249756\n",
      "validation loss = 1.9191126823425293\n",
      "validation loss = 1.6771055459976196\n",
      "validation loss = 1.7327431440353394\n",
      "validation loss = 2.041381359100342\n",
      "validation loss = 2.03399920463562\n",
      "validation loss = 2.0740039348602295\n",
      "validation loss = 2.1920201778411865\n",
      "validation loss = 2.088324546813965\n",
      "validation loss = 2.0658838748931885\n",
      "validation loss = 2.2221639156341553\n",
      "validation loss = 1.8267802000045776\n",
      "validation loss = 2.485724687576294\n",
      "validation loss = 1.7362650632858276\n",
      "validation loss = 1.8847161531448364\n",
      "validation loss = 1.8348102569580078\n",
      "validation loss = 2.241964101791382\n",
      "validation loss = 1.7525920867919922\n",
      "validation loss = 1.661713719367981\n",
      "validation loss = 2.37396502494812\n",
      "validation loss = 1.8174495697021484\n",
      "validation loss = 2.212799549102783\n",
      "validation loss = 2.2376134395599365\n",
      "validation loss = 1.6306259632110596\n",
      "validation loss = 2.0414512157440186\n",
      "validation loss = 2.0150671005249023\n",
      "validation loss = 1.9041308164596558\n",
      "validation loss = 2.0345754623413086\n",
      "validation loss = 2.0043792724609375\n",
      "validation loss = 1.7007956504821777\n",
      "validation loss = 2.0239434242248535\n",
      "validation loss = 1.5863860845565796\n",
      "validation loss = 2.01786208152771\n",
      "validation loss = 1.8359588384628296\n",
      "validation loss = 2.5623488426208496\n",
      "validation loss = 2.1596484184265137\n",
      "validation loss = 2.32407808303833\n",
      "validation loss = 1.7444440126419067\n",
      "validation loss = 1.9159531593322754\n",
      "validation loss = 2.065047264099121\n",
      "validation loss = 2.3130979537963867\n",
      "validation loss = 1.9075514078140259\n",
      "validation loss = 1.4179993867874146\n",
      "validation loss = 2.192519426345825\n",
      "validation loss = 1.7551122903823853\n",
      "validation loss = 1.5053266286849976\n",
      "validation loss = 2.095930814743042\n",
      "validation loss = 1.8835783004760742\n",
      "Val loss = 1.990261286497116 .. Accuracy = 0.2249 \n",
      "\n",
      "\t*** Saved checkpoint in checkpoint/model_weights/weights_epoch_0.pth.tar ***\n",
      "\n",
      "training @ epoch 1 .. loss = 1.5960136651992798\n",
      "training @ epoch 1 .. loss = 1.958694577217102\n",
      "training @ epoch 1 .. loss = 1.2297921180725098\n",
      "training @ epoch 1 .. loss = 1.5058045387268066\n",
      "training @ epoch 1 .. loss = 1.5092567205429077\n",
      "training @ epoch 1 .. loss = 2.3006019592285156\n",
      "training @ epoch 1 .. loss = 1.4051495790481567\n",
      "training @ epoch 1 .. loss = 1.6235324144363403\n",
      "training @ epoch 1 .. loss = 1.695486068725586\n",
      "training @ epoch 1 .. loss = 1.3422328233718872\n",
      "training @ epoch 1 .. loss = 1.95335054397583\n",
      "training @ epoch 1 .. loss = 1.6829934120178223\n",
      "training @ epoch 1 .. loss = 1.696608066558838\n",
      "training @ epoch 1 .. loss = 1.503034234046936\n",
      "training @ epoch 1 .. loss = 1.4126166105270386\n",
      "training @ epoch 1 .. loss = 1.583591103553772\n",
      "training @ epoch 1 .. loss = 1.8153338432312012\n",
      "training @ epoch 1 .. loss = 1.6408569812774658\n",
      "training @ epoch 1 .. loss = 1.7931331396102905\n",
      "training @ epoch 1 .. loss = 1.9065653085708618\n",
      "training @ epoch 1 .. loss = 1.3684108257293701\n",
      "training @ epoch 1 .. loss = 1.5247619152069092\n",
      "training @ epoch 1 .. loss = 1.2474863529205322\n",
      "training @ epoch 1 .. loss = 1.6703417301177979\n",
      "training @ epoch 1 .. loss = 1.4861845970153809\n",
      "training @ epoch 1 .. loss = 1.7667678594589233\n",
      "training @ epoch 1 .. loss = 1.668427586555481\n",
      "training @ epoch 1 .. loss = 1.5192339420318604\n",
      "training @ epoch 1 .. loss = 1.7931830883026123\n",
      "training @ epoch 1 .. loss = 1.3401494026184082\n",
      "training @ epoch 1 .. loss = 1.374416708946228\n",
      "training @ epoch 1 .. loss = 1.6884613037109375\n",
      "training @ epoch 1 .. loss = 1.6454319953918457\n",
      "training @ epoch 1 .. loss = 1.5512700080871582\n",
      "training @ epoch 1 .. loss = 1.573905110359192\n",
      "training @ epoch 1 .. loss = 1.9102181196212769\n",
      "training @ epoch 1 .. loss = 1.907267689704895\n",
      "training @ epoch 1 .. loss = 1.4679853916168213\n",
      "training @ epoch 1 .. loss = 1.724003553390503\n",
      "training @ epoch 1 .. loss = 1.5558831691741943\n",
      "training @ epoch 1 .. loss = 1.6708635091781616\n",
      "training @ epoch 1 .. loss = 1.82921302318573\n",
      "training @ epoch 1 .. loss = 1.6665916442871094\n",
      "training @ epoch 1 .. loss = 1.9938827753067017\n",
      "training @ epoch 1 .. loss = 1.5280917882919312\n",
      "training @ epoch 1 .. loss = 1.26810622215271\n",
      "training @ epoch 1 .. loss = 1.7897852659225464\n",
      "training @ epoch 1 .. loss = 1.6317601203918457\n",
      "training @ epoch 1 .. loss = 1.2206155061721802\n",
      "training @ epoch 1 .. loss = 1.5757906436920166\n",
      "training @ epoch 1 .. loss = 1.4588252305984497\n",
      "training @ epoch 1 .. loss = 1.6058979034423828\n",
      "training @ epoch 1 .. loss = 1.7691479921340942\n",
      "training @ epoch 1 .. loss = 1.6752536296844482\n",
      "training @ epoch 1 .. loss = 1.774681806564331\n",
      "training @ epoch 1 .. loss = 1.7213823795318604\n",
      "training @ epoch 1 .. loss = 1.544938564300537\n",
      "training @ epoch 1 .. loss = 1.6513254642486572\n",
      "training @ epoch 1 .. loss = 1.6379183530807495\n",
      "training @ epoch 1 .. loss = 1.6662567853927612\n",
      "training @ epoch 1 .. loss = 1.8663312196731567\n",
      "training @ epoch 1 .. loss = 1.7974772453308105\n",
      "training @ epoch 1 .. loss = 1.655434489250183\n",
      "training @ epoch 1 .. loss = 1.397302269935608\n",
      "training @ epoch 1 .. loss = 1.6893928050994873\n",
      "training @ epoch 1 .. loss = 1.569745659828186\n",
      "training @ epoch 1 .. loss = 1.9682201147079468\n",
      "training @ epoch 1 .. loss = 1.3222739696502686\n",
      "training @ epoch 1 .. loss = 1.6564174890518188\n",
      "training @ epoch 1 .. loss = 1.6599218845367432\n",
      "training @ epoch 1 .. loss = 1.38216233253479\n",
      "training @ epoch 1 .. loss = 1.5080468654632568\n",
      "training @ epoch 1 .. loss = 1.6237843036651611\n",
      "training @ epoch 1 .. loss = 1.516498327255249\n",
      "training @ epoch 1 .. loss = 1.6448932886123657\n",
      "training @ epoch 1 .. loss = 1.7615424394607544\n",
      "training @ epoch 1 .. loss = 2.522618055343628\n",
      "training @ epoch 1 .. loss = 1.4378608465194702\n",
      "training @ epoch 1 .. loss = 1.6312963962554932\n",
      "training @ epoch 1 .. loss = 1.517061710357666\n",
      "training @ epoch 1 .. loss = 1.3001257181167603\n",
      "training @ epoch 1 .. loss = 1.3784652948379517\n",
      "training @ epoch 1 .. loss = 1.424619197845459\n",
      "training @ epoch 1 .. loss = 1.8393471240997314\n",
      "training @ epoch 1 .. loss = 1.5867522954940796\n",
      "training @ epoch 1 .. loss = 1.5173345804214478\n",
      "training @ epoch 1 .. loss = 1.418514609336853\n",
      "training @ epoch 1 .. loss = 1.5578137636184692\n",
      "training @ epoch 1 .. loss = 1.4102497100830078\n",
      "training @ epoch 1 .. loss = 1.4190983772277832\n",
      "training @ epoch 1 .. loss = 1.788415551185608\n",
      "training @ epoch 1 .. loss = 1.7357442378997803\n",
      "training @ epoch 1 .. loss = 1.3171015977859497\n",
      "training @ epoch 1 .. loss = 1.6192578077316284\n",
      "training @ epoch 1 .. loss = 1.3339591026306152\n",
      "training @ epoch 1 .. loss = 1.5372812747955322\n",
      "training @ epoch 1 .. loss = 1.5829041004180908\n",
      "training @ epoch 1 .. loss = 1.7835503816604614\n",
      "training @ epoch 1 .. loss = 1.5564318895339966\n",
      "training @ epoch 1 .. loss = 1.462146520614624\n",
      "training @ epoch 1 .. loss = 1.6890804767608643\n",
      "training @ epoch 1 .. loss = 2.0989673137664795\n",
      "training @ epoch 1 .. loss = 1.6198967695236206\n",
      "training @ epoch 1 .. loss = 1.3009744882583618\n",
      "training @ epoch 1 .. loss = 1.75521719455719\n",
      "training @ epoch 1 .. loss = 1.6101428270339966\n",
      "training @ epoch 1 .. loss = 1.4235541820526123\n",
      "training @ epoch 1 .. loss = 1.3150246143341064\n",
      "training @ epoch 1 .. loss = 1.4151997566223145\n",
      "training @ epoch 1 .. loss = 1.5149695873260498\n",
      "training @ epoch 1 .. loss = 1.4334914684295654\n",
      "training @ epoch 1 .. loss = 1.7770131826400757\n",
      "training @ epoch 1 .. loss = 1.7693631649017334\n",
      "training @ epoch 1 .. loss = 1.8209127187728882\n",
      "training @ epoch 1 .. loss = 1.704500675201416\n",
      "training @ epoch 1 .. loss = 1.5296574831008911\n",
      "training @ epoch 1 .. loss = 1.437576413154602\n",
      "training @ epoch 1 .. loss = 1.5880801677703857\n",
      "training @ epoch 1 .. loss = 1.433656930923462\n",
      "training @ epoch 1 .. loss = 1.4295955896377563\n",
      "training @ epoch 1 .. loss = 1.8880763053894043\n",
      "training @ epoch 1 .. loss = 1.6144472360610962\n",
      "training @ epoch 1 .. loss = 1.5605794191360474\n",
      "training @ epoch 1 .. loss = 1.4561231136322021\n",
      "training @ epoch 1 .. loss = 1.8499031066894531\n",
      "training @ epoch 1 .. loss = 1.448676347732544\n",
      "training @ epoch 1 .. loss = 1.5062806606292725\n",
      "training @ epoch 1 .. loss = 1.6052714586257935\n",
      "training @ epoch 1 .. loss = 1.3890706300735474\n",
      "training @ epoch 1 .. loss = 1.931448221206665\n",
      "training @ epoch 1 .. loss = 1.9234000444412231\n",
      "training @ epoch 1 .. loss = 1.435494303703308\n",
      "training @ epoch 1 .. loss = 1.6926993131637573\n",
      "training @ epoch 1 .. loss = 1.490052580833435\n",
      "training @ epoch 1 .. loss = 1.5616357326507568\n",
      "training @ epoch 1 .. loss = 1.6418672800064087\n",
      "training @ epoch 1 .. loss = 1.8344175815582275\n",
      "training @ epoch 1 .. loss = 1.734272837638855\n",
      "training @ epoch 1 .. loss = 1.9112598896026611\n",
      "training @ epoch 1 .. loss = 1.7164901494979858\n",
      "training @ epoch 1 .. loss = 1.303353190422058\n",
      "training @ epoch 1 .. loss = 1.5249334573745728\n",
      "training @ epoch 1 .. loss = 1.7094141244888306\n",
      "training @ epoch 1 .. loss = 1.3159699440002441\n",
      "training @ epoch 1 .. loss = 1.6459988355636597\n",
      "training @ epoch 1 .. loss = 1.7393875122070312\n",
      "training @ epoch 1 .. loss = 1.7722527980804443\n",
      "training @ epoch 1 .. loss = 1.236390233039856\n",
      "training @ epoch 1 .. loss = 1.4191721677780151\n",
      "training @ epoch 1 .. loss = 1.7766724824905396\n",
      "training @ epoch 1 .. loss = 1.5057469606399536\n",
      "training @ epoch 1 .. loss = 1.3018038272857666\n",
      "training @ epoch 1 .. loss = 1.5181307792663574\n",
      "training @ epoch 1 .. loss = 1.569736361503601\n",
      "training @ epoch 1 .. loss = 1.3414982557296753\n",
      "training @ epoch 1 .. loss = 1.652387261390686\n",
      "training @ epoch 1 .. loss = 1.6084274053573608\n",
      "training @ epoch 1 .. loss = 1.790582299232483\n",
      "training @ epoch 1 .. loss = 1.3918544054031372\n",
      "training @ epoch 1 .. loss = 1.5490760803222656\n",
      "training @ epoch 1 .. loss = 1.2395589351654053\n",
      "training @ epoch 1 .. loss = 1.6959317922592163\n",
      "training @ epoch 1 .. loss = 1.341787338256836\n",
      "training @ epoch 1 .. loss = 1.2291113138198853\n",
      "training @ epoch 1 .. loss = 1.630998134613037\n",
      "training @ epoch 1 .. loss = 1.26505708694458\n",
      "training @ epoch 1 .. loss = 1.7692854404449463\n",
      "training @ epoch 1 .. loss = 1.159089207649231\n",
      "training @ epoch 1 .. loss = 1.725765585899353\n",
      "training @ epoch 1 .. loss = 1.3795146942138672\n",
      "training @ epoch 1 .. loss = 1.2012250423431396\n",
      "training @ epoch 1 .. loss = 1.327958345413208\n",
      "training @ epoch 1 .. loss = 1.5554625988006592\n",
      "training @ epoch 1 .. loss = 1.7860395908355713\n",
      "training @ epoch 1 .. loss = 1.5575687885284424\n",
      "training @ epoch 1 .. loss = 1.954640507698059\n",
      "training @ epoch 1 .. loss = 1.3990559577941895\n",
      "training @ epoch 1 .. loss = 1.4552439451217651\n",
      "training @ epoch 1 .. loss = 1.6573354005813599\n",
      "training @ epoch 1 .. loss = 1.6049963235855103\n",
      "training @ epoch 1 .. loss = 1.8938418626785278\n",
      "training @ epoch 1 .. loss = 1.4106523990631104\n",
      "training @ epoch 1 .. loss = 1.3359326124191284\n",
      "training @ epoch 1 .. loss = 1.5636239051818848\n",
      "training @ epoch 1 .. loss = 1.864733099937439\n",
      "training @ epoch 1 .. loss = 1.7352896928787231\n",
      "training @ epoch 1 .. loss = 1.4618719816207886\n",
      "training @ epoch 1 .. loss = 1.4257289171218872\n",
      "training @ epoch 1 .. loss = 1.3245033025741577\n",
      "training @ epoch 1 .. loss = 1.8021827936172485\n",
      "training @ epoch 1 .. loss = 1.6554142236709595\n",
      "training @ epoch 1 .. loss = 1.7017120122909546\n",
      "training @ epoch 1 .. loss = 1.711243987083435\n",
      "training @ epoch 1 .. loss = 1.5563422441482544\n",
      "training @ epoch 1 .. loss = 1.1895259618759155\n",
      "training @ epoch 1 .. loss = 1.3711098432540894\n",
      "training @ epoch 1 .. loss = 1.4052882194519043\n",
      "training @ epoch 1 .. loss = 1.5222142934799194\n",
      "training @ epoch 1 .. loss = 1.4289015531539917\n",
      "training @ epoch 1 .. loss = 1.4958728551864624\n",
      "training @ epoch 1 .. loss = 1.5371259450912476\n",
      "training @ epoch 1 .. loss = 1.5155264139175415\n",
      "training @ epoch 1 .. loss = 1.8696306943893433\n",
      "training @ epoch 1 .. loss = 1.6020532846450806\n",
      "training @ epoch 1 .. loss = 1.5033591985702515\n",
      "training @ epoch 1 .. loss = 1.692228078842163\n",
      "training @ epoch 1 .. loss = 1.5162657499313354\n",
      "training @ epoch 1 .. loss = 1.7251425981521606\n",
      "training @ epoch 1 .. loss = 1.2538437843322754\n",
      "training @ epoch 1 .. loss = 1.6100643873214722\n",
      "training @ epoch 1 .. loss = 1.2399983406066895\n",
      "training @ epoch 1 .. loss = 1.3833332061767578\n",
      "training @ epoch 1 .. loss = 1.2247000932693481\n",
      "training @ epoch 1 .. loss = 1.5971308946609497\n",
      "training @ epoch 1 .. loss = 1.2196804285049438\n",
      "training @ epoch 1 .. loss = 1.694195032119751\n",
      "training @ epoch 1 .. loss = 1.60861337184906\n",
      "training @ epoch 1 .. loss = 1.4364827871322632\n",
      "training @ epoch 1 .. loss = 1.314727783203125\n",
      "training @ epoch 1 .. loss = 1.518189549446106\n",
      "training @ epoch 1 .. loss = 1.761101484298706\n",
      "training @ epoch 1 .. loss = 1.7689554691314697\n",
      "training @ epoch 1 .. loss = 1.718599557876587\n",
      "training @ epoch 1 .. loss = 1.8359886407852173\n",
      "training @ epoch 1 .. loss = 1.8651341199874878\n",
      "training @ epoch 1 .. loss = 2.042881965637207\n",
      "training @ epoch 1 .. loss = 1.914789080619812\n",
      "training @ epoch 1 .. loss = 1.29914128780365\n",
      "training @ epoch 1 .. loss = 1.9087127447128296\n",
      "training @ epoch 1 .. loss = 2.0039238929748535\n",
      "training @ epoch 1 .. loss = 1.5719590187072754\n",
      "training @ epoch 1 .. loss = 1.5050450563430786\n",
      "training @ epoch 1 .. loss = 1.8162579536437988\n",
      "training @ epoch 1 .. loss = 1.8103811740875244\n",
      "training @ epoch 1 .. loss = 1.7126437425613403\n",
      "training @ epoch 1 .. loss = 1.5740777254104614\n",
      "training @ epoch 1 .. loss = 1.8177164793014526\n",
      "training @ epoch 1 .. loss = 1.8189674615859985\n",
      "training @ epoch 1 .. loss = 1.4219995737075806\n",
      "training @ epoch 1 .. loss = 1.8032244443893433\n",
      "training @ epoch 1 .. loss = 1.5550363063812256\n",
      "training @ epoch 1 .. loss = 1.6505519151687622\n",
      "training @ epoch 1 .. loss = 1.4698094129562378\n",
      "training @ epoch 1 .. loss = 1.6692248582839966\n",
      "training @ epoch 1 .. loss = 1.512986660003662\n",
      "training @ epoch 1 .. loss = 1.602065920829773\n",
      "training @ epoch 1 .. loss = 1.552586317062378\n",
      "training @ epoch 1 .. loss = 1.4529526233673096\n",
      "training @ epoch 1 .. loss = 1.7641781568527222\n",
      "training @ epoch 1 .. loss = 1.5356848239898682\n",
      "training @ epoch 1 .. loss = 1.236785888671875\n",
      "training @ epoch 1 .. loss = 1.4831161499023438\n",
      "training @ epoch 1 .. loss = 1.7367022037506104\n",
      "training @ epoch 1 .. loss = 1.7596945762634277\n",
      "training @ epoch 1 .. loss = 1.1505191326141357\n",
      "training @ epoch 1 .. loss = 1.2693220376968384\n",
      "training @ epoch 1 .. loss = 1.5494499206542969\n",
      "training @ epoch 1 .. loss = 1.4573932886123657\n",
      "training @ epoch 1 .. loss = 1.4485855102539062\n",
      "training @ epoch 1 .. loss = 1.7081053256988525\n",
      "training @ epoch 1 .. loss = 1.6180909872055054\n",
      "training @ epoch 1 .. loss = 1.7049508094787598\n",
      "training @ epoch 1 .. loss = 1.852281928062439\n",
      "training @ epoch 1 .. loss = 1.7615196704864502\n",
      "training @ epoch 1 .. loss = 1.2183406352996826\n",
      "training @ epoch 1 .. loss = 1.4285520315170288\n",
      "training @ epoch 1 .. loss = 1.4817593097686768\n",
      "training @ epoch 1 .. loss = 1.3495622873306274\n",
      "training @ epoch 1 .. loss = 1.4040971994400024\n",
      "training @ epoch 1 .. loss = 1.5281111001968384\n",
      "training @ epoch 1 .. loss = 1.5958781242370605\n",
      "training @ epoch 1 .. loss = 1.940209150314331\n",
      "training @ epoch 1 .. loss = 1.8314590454101562\n",
      "training @ epoch 1 .. loss = 1.66224205493927\n",
      "training @ epoch 1 .. loss = 1.367708444595337\n",
      "training @ epoch 1 .. loss = 1.4951978921890259\n",
      "training @ epoch 1 .. loss = 1.4996044635772705\n",
      "training @ epoch 1 .. loss = 1.460412859916687\n",
      "training @ epoch 1 .. loss = 1.7299458980560303\n",
      "training @ epoch 1 .. loss = 1.6198877096176147\n",
      "training @ epoch 1 .. loss = 1.3508563041687012\n",
      "training @ epoch 1 .. loss = 1.6846786737442017\n",
      "training @ epoch 1 .. loss = 1.475873589515686\n",
      "training @ epoch 1 .. loss = 1.3953064680099487\n",
      "training @ epoch 1 .. loss = 1.4821298122406006\n",
      "training @ epoch 1 .. loss = 1.3545373678207397\n",
      "training @ epoch 1 .. loss = 1.6882778406143188\n",
      "training @ epoch 1 .. loss = 1.4464560747146606\n",
      "training @ epoch 1 .. loss = 1.3204721212387085\n",
      "training @ epoch 1 .. loss = 1.4612380266189575\n",
      "training @ epoch 1 .. loss = 1.2811938524246216\n",
      "training @ epoch 1 .. loss = 2.0772156715393066\n",
      "training @ epoch 1 .. loss = 1.702101230621338\n",
      "training @ epoch 1 .. loss = 1.3933312892913818\n",
      "training @ epoch 1 .. loss = 1.6170837879180908\n",
      "training @ epoch 1 .. loss = 1.4861501455307007\n",
      "training @ epoch 1 .. loss = 1.7281869649887085\n",
      "training @ epoch 1 .. loss = 2.0519521236419678\n",
      "training @ epoch 1 .. loss = 1.19893479347229\n",
      "training @ epoch 1 .. loss = 1.4433516263961792\n",
      "training @ epoch 1 .. loss = 1.517773151397705\n",
      "training @ epoch 1 .. loss = 1.9433671236038208\n",
      "training @ epoch 1 .. loss = 1.4495227336883545\n",
      "training @ epoch 1 .. loss = 1.2188915014266968\n",
      "training @ epoch 1 .. loss = 1.3220558166503906\n",
      "training @ epoch 1 .. loss = 1.576305627822876\n",
      "training @ epoch 1 .. loss = 1.7201290130615234\n",
      "training @ epoch 1 .. loss = 1.4752131700515747\n",
      "training @ epoch 1 .. loss = 2.0574638843536377\n",
      "training @ epoch 1 .. loss = 1.735117793083191\n",
      "training @ epoch 1 .. loss = 1.5812608003616333\n",
      "training @ epoch 1 .. loss = 1.5224403142929077\n",
      "training @ epoch 1 .. loss = 1.5032353401184082\n",
      "training @ epoch 1 .. loss = 1.5115374326705933\n",
      "training @ epoch 1 .. loss = 1.3331173658370972\n",
      "training @ epoch 1 .. loss = 1.556524395942688\n",
      "training @ epoch 1 .. loss = 1.8956637382507324\n",
      "training @ epoch 1 .. loss = 1.5940701961517334\n",
      "training @ epoch 1 .. loss = 1.5453208684921265\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9fd86ae8936b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 앞서 작성한 main 함수 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-9fd86ae8936b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# =========== train / validate ===========\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_xception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_xception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9fd86ae8936b>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, dataloader, epoch)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_xception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch, 1, 48, 48) -> images.shape[0]을 mini batch size로 나중에 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/NLP/vision_dataset_final_sol.ipynb\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# tensorboard 만들기\n",
    "writer = tensorboard.SummaryWriter('checkpoint/tensorboard')\n",
    "mini_xception = Mini_Xception()\n",
    "\n",
    "def main(): # 코드가 실행될 main 함수를 만들어봅시다.\n",
    "   \n",
    "    # ========= dataloaders ===========\n",
    "    train_dataloader = create_train_dataloader(root='./data', batch_size = 15)\n",
    "    test_dataloader = create_val_dataloader(root='./data', batch_size=15)    \n",
    "    # ========= load =========== \n",
    "    print(\"---Training---\\n\")\n",
    "\n",
    "    for epoch in range(0, 5):\n",
    "        # =========== train / validate ===========\n",
    "        train_loss = train_one_epoch(mini_xception, train_dataloader, epoch)\n",
    "        val_loss, accuracy= validate(mini_xception, test_dataloader, epoch)\n",
    "        \n",
    "        # tensorboard에 loss와 정확도 나타내기(매 epoch 마다)\n",
    "        writer.add_scalar('train_loss',train_loss, epoch)\n",
    "        writer.add_scalar('val_loss',val_loss, epoch)\n",
    "        writer.add_scalar('accuracy',accuracy, epoch)\n",
    " \n",
    "        # 매 epoch 마다 checkpoint로 model을 저장한다.\n",
    "        if epoch % 1 == 0:\n",
    "            checkpoint_state = {\n",
    "                'mini_xception': mini_xception.state_dict(),\n",
    "                \"epoch\": epoch\n",
    "            }\n",
    "            savepath = os.path.join('checkpoint/model_weights', f'weights_epoch_{epoch}.pth.tar')\n",
    "            torch.save(checkpoint_state, savepath)\n",
    "            print(f'\\n\\t*** Saved checkpoint in {savepath} ***\\n')\n",
    "    writer.close() # Tensorboard 닫기\n",
    "\n",
    "def train_one_epoch(model, dataloader, epoch): # train 과정에서의 손실을 계산하는 함수 작성\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    losses = [] # 손실 저장용 array\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(mini_xception.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device) # (batch, 1, 48, 48) -> images.shape[0]을 mini batch size로 나중에 설정\n",
    "        labels = labels.to(device) # (batch,)\n",
    "        emotions = model(images) # -> 예측값\n",
    "\n",
    "        # (batch, 7, 1, 1) -> (batch, 7)\n",
    "        emotions = torch.squeeze(emotions) # Returns a tensor with all the dimensions of input of size 1 removed.\n",
    "        loss = criterion(emotions, labels) # 예측값과 label간 loss\n",
    "        losses.append(loss.cpu().item())\n",
    "        print(f'training @ epoch {epoch} .. loss = {loss.item()}')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return np.mean(losses).item()\n",
    "\n",
    "def validate(model, dataloader, epoch): \n",
    "  # 중간미션 1에서 with torch.no_grad(): 부분에 작성하였던 test accuracy를 구하는 방법을 떠올려보면 됩니다. \n",
    "  # train 과정에서의 손실도 중요하나 최종적으로 random data을 넣어서 test를 한 후의 정확도를 얻어야 합니다.\n",
    "    model.eval() # dropout layer처럼 학습에는 사용하나 evaluation에서는 사용하지 않는 layer에 대해 .eval()을 먼저 설정해주면 그 layer은 동작하지 않습니다.\n",
    "    model.to(device)\n",
    "    losses = []\n",
    "    total_pred = []\n",
    "    total_labels = []\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad(): # 학습이 x 모델 성능 평가 따라서 autograd하지 않음!!\n",
    "        for images, labels in dataloader:\n",
    "            mini_batch = images.shape[0]\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            emotions = model(images)\n",
    "            emotions = torch.squeeze(emotions)\n",
    "            emotions = emotions.reshape(mini_batch, -1) # mini_batch로 shape 맞춤(계산위해서)\n",
    "\n",
    "            loss = criterion(emotions, labels)            \n",
    "            losses.append(loss.cpu().item())\n",
    "\n",
    "            # # ============== Evaluation ===============\n",
    "            # index of the max value of each sample (shape = (batch,))\n",
    "            _, indexes = torch.max(emotions, axis=1)\n",
    "            total_pred.extend(indexes.cpu().detach().numpy())\n",
    "            total_labels.extend(labels.cpu().detach().numpy())\n",
    "            \n",
    "            print(f'validation loss = {loss.item()}')\n",
    "\n",
    "        val_loss = np.mean(losses).item()\n",
    "        accuracy = accuracy_score(total_labels, total_pred)\n",
    "        \n",
    "        \n",
    "        print(f'Val loss = {val_loss} .. Accuracy = {accuracy:.4f} ')\n",
    "\n",
    "        return val_loss, accuracy\n",
    "\n",
    "if __name__ == \"__main__\": # 앞서 작성한 main 함수 실행\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "executionInfo": {
     "elapsed": 4844,
     "status": "ok",
     "timestamp": 1660383985522,
     "user": {
      "displayName": "­권태희 / 학생 / 전기·정보공학부",
      "userId": "01216604526634043672"
     },
     "user_tz": -540
    },
    "id": "IXSstWbFV6E5",
    "outputId": "c78ce49b-7223-4669-a13c-ffce64b62c14"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        (async () => {\n",
       "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
       "            url.searchParams.set('tensorboardColab', 'true');\n",
       "            const iframe = document.createElement('iframe');\n",
       "            iframe.src = url;\n",
       "            iframe.setAttribute('width', '100%');\n",
       "            iframe.setAttribute('height', '800');\n",
       "            iframe.setAttribute('frameborder', 0);\n",
       "            document.body.appendChild(iframe);\n",
       "        })();\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 저장해놓은 텐서보드 로드하기(in colab) - loss와 accuracy의 경향 확인\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {'checkpoint/tensorboard'}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vision_train_final_sol.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
