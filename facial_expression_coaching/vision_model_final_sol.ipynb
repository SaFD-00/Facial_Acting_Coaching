{"cells":[{"cell_type":"code","execution_count":null,"id":"ab0716d3","metadata":{"id":"ab0716d3"},"outputs":[],"source":["from torch.nn.modules.activation import ReLU\n","\n","import torch\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":null,"id":"ddcd66d8","metadata":{"id":"ddcd66d8"},"outputs":[],"source":["def conv_bn_relu(in_channels, out_channels, kernel_size=3, stride=1, padding=0):\n","    \"\"\"\n","    합성곱 연산, Batch Normalization, ReLU 활성함수를 연속적으로 거치도록 하는 Sequential을 return하는 함수\n","\n","    매개변수(Parameters)\n","    ----------------------\n","    in_channels: int형, 입력으로 들어오는 이미지의 채널 개수\n","    out_channels: int형, 출력으로 반환할 이미지의 채널 개수\n","    kernel_size: int 혹은 tuple 형, 사용할 필터의 크기 정보, default 값 3\n","    stride: int 혹은 tuple 형, 스트라이드 값, defalut 값 1\n","    padding: int 혹은 tuple 혹은 str형, 패딩에 대한 정보, defalut 값 0(패딩 없음)\n","\n","    반환 값(Returns)\n","    ----------------------\n","    합성곱 연산, Batch Normalization, ReLU 활성함수를 연속적으로 거치도록 하는 torch.nn.Sequential\n","    \"\"\"\n","    return nn.Sequential(\n","        # 입력받은 매개변수에 따라, 합성곱 연산을 진행\n","        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n","        # 배치 정규화 진행\n","        nn.BatchNorm2d(out_channels),\n","        # 활성함수인 ReLU 함수 거치기\n","        nn.ReLU(inplace=True)\n","    )"]},{"cell_type":"code","execution_count":null,"id":"cf35fa24","metadata":{"id":"cf35fa24"},"outputs":[],"source":["def SeparableConv2D(in_channels, out_channels, kernel=3):\n","    \"\"\"\n","    Separable Convolution 연산을 진행하는 Sequential을 return하는 함수\n","\n","    매개변수(Parameters)\n","    ----------------------\n","    in_channels: int형, 입력으로 들어오는 이미지의 채널 개수\n","    out_channels: int형, 출력으로 반환할 이미지의 채널 개수\n","    kernel: int 혹은 tuple 형, 사용할 필터의 크기 정보, default 값 3\n","    \n","    반환 값(Returns)\n","    ----------------------\n","    Separable Convolution 연산을 진행하는 Sequential\n","    \"\"\"\n","    return nn.Sequential(\n","        # 입력받은 채널의 개수를 보존하는 형태로, 채널 수가 1인 필터를 합성곱 연산\n","        nn.Conv2d(in_channels, in_channels, kernel_size=kernel, stride=1, groups=in_channels, padding=1, bias=False),\n","        # 1x1 합성곱 연산 진행, 채널 개수를 원하는 출력 채널 개수로 조정\n","        nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n","    )"]},{"cell_type":"code","execution_count":null,"id":"a11d5dd5","metadata":{"id":"a11d5dd5"},"outputs":[],"source":["class ResidualXceptionBlock(nn.Module):\n","    \"\"\"\n","    MiniXception 구조의 핵심인 부분으로, 잔차 연결로 두 경로의 계층 연산을 합해주는 클래스\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels, kernel=3):\n","        \"\"\"\n","        필요한 계층을 정의하는 부분들이 담긴 생성자(constructor)\n","\n","        매개변수(Parameters)\n","        ----------------------\n","        in_channels: int형, 입력으로 들어오는 이미지의 채널 개수\n","        out_channels: int형, 출력으로 반환할 이미지의 채널 개수\n","        kernel: int 혹은 tuple 형, 사용할 필터의 크기 정보, default 값 3\n","        \"\"\"\n","        # 상속받은 nn.Module 클래스의 생성자 호출\n","        super().__init__()\n","\n","        # 그림 21에서, ResidualXceptionBlock을 구성하는 4개의 사각형 중 좌측 가장 하단\n","        # 이 계층에서의 합성곱 연산을 통해 출력 데이터의 채널 수로 조정\n","        # Separable convolution 연산을 진행하는 계층, Sequential 형태. 앞서 정의한 함수 활용\n","        self.depthwise_conv1 = SeparableConv2D(in_channels, out_channels, kernel)\n","        # 배치 정규화 진행\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        # 활성함수로 ReLU 함수를 사용\n","        self.relu1 = nn.ReLU(inplace=True)\n","\n","        # 그림 21에서, ResidualXceptionBlock을 구성하는 4개의 사각형 중 좌측 가운데\n","        # 앞선 계층에서 출력 데이터의 채널 개수를 맞추었으므로, 채널 개수에는 변화를 주지 않음\n","        # Separable convolution 연산을 진행하는 계층, Sequential 형태. 앞서 정의한 함수 활용\n","        self.depthwise_conv2 = SeparableConv2D(out_channels, out_channels, kernel)\n","        # 배치 정규화 진행\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        # 그림 21에서, ResidualXceptionBlock을 구성하는 4개의 사각형 중 좌측 상단\n","        # 최대 풀링 진행\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n","        \n","        # 그림 21에서, ResidualXceptionBlock을 구성하는 4개의 사각형 중 우측\n","        # 잔차 연결을 진행하기 위한 갈래의 계층을 구현\n","        # 합성곱 연산 진행, 필요한 출력 데이터의 채널 수가 되도록 조정\n","        self.residual_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n","        # 배치 정규화 진행\n","        self.residual_bn = nn.BatchNorm2d(out_channels)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        순전파를 진행하도록 하는 함수\n","\n","        매개변수(Parameters)\n","        ----------------------\n","        x: Tensor, 입력 데이터\n","        \"\"\"\n","        # 그림 21에서, ResidualXceptionBlock을 구성하는 두 갈래 중 우측\n","        # 우측 갈래를 따른 순전파 진행 결과를 residual에 저장\n","        residual = self.residual_conv(x)\n","        residual = self.residual_bn(residual)\n","        \n","        # 그림 21에서, ResidualXceptionBlock을 구성하는 두 갈래 중 좌측\n","        # 우측 갈래를 따른 순전파 진행 결과를 x에 저장\n","        x = self.depthwise_conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu1(x)\n","        x = self.depthwise_conv2(x)\n","        x = self.bn2(x)\n","        x = self.maxpool(x)\n","\n","        # 두 갈래의 순전파 결과를 합한 Tensor 결과를 반환하여 잔차 연결 구현\n","        return x + residual"]},{"cell_type":"code","execution_count":null,"id":"975327a8","metadata":{"id":"975327a8"},"outputs":[],"source":["class Mini_Xception(nn.Module):\n","    \"\"\"\n","    전체 MiniXception 구조를 구현한 클래스\n","    \"\"\"\n","    def __init__(self):\n","        \"\"\"\n","        필요한 계층을 정의하는 부분들이 담긴 생성자(constructor)\n","        \"\"\"\n","        # 상속받은 nn.Module 클래스의 생성자 호출\n","        super().__init__()\n","\n","        # 그림 21에서, ResidualXceptionBlock 이전의 합성곱-배치 정규화-ReLU 계층\n","        self.conv1 = conv_bn_relu(1, 8, kernel_size=3, stride=1, padding=0)\n","        self.conv2 = conv_bn_relu(8, 8, kernel_size=3, stride=1, padding=0)\n","        \n","        # 그림 21에서, ResidualXceptionBlock 4개를 모아둔 부분\n","        # 순전파가 진행될수록, 이미지 채널 개수를 2배씩 증가\n","        # 이전 계층의 출력 채널 개수가 다음 채널의 입력 채널의 개수와 동일하도록 설정 필요\n","        # 채널 개수를 증가시키는 점에 대한 기본적인 아이디어가 궁금하다면, VGGNet이라는 구조에 대해 찾아보자.\n","        self.residual_blocks = nn.ModuleList([\n","            ResidualXceptionBlock(8 , 16),\n","            ResidualXceptionBlock(16, 32),\n","            ResidualXceptionBlock(32, 64),\n","            ResidualXceptionBlock(64, 128)            \n","        ])\n","\n","        # 그림 21에서, ResidualXceptionBlock 4개를 거친 이후의 부분\n","        # 합성곱 계층\n","        # Global Average Pooling 단계로 넘어가기 직전의 채널 수를 7로 설정함에 주목할 것.\n","        self.conv3 = nn.Conv2d(128, 7, kernel_size=3, stride=1, padding=1)\n","        # Global Average Pooling 계층\n","        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        순전파를 진행하도록 하는 함수\n","\n","        매개변수(Parameters)\n","        ----------------------\n","        x: Tensor, 입력 데이터\n","        \"\"\"        \n","        # 그림 21에서, ResidualXceptionBlock 이전의 순전파\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","\n","        # 그림 21에서, ResidualXceptionBlock 4개에 대한 순전파\n","        # ModuleList를 순회하면서, 저장된 계층들을 차례로 적용하도록 함\n","        for block in self.residual_blocks:\n","            x = block(x)\n","\n","        # 그림 21에서, ResidualXceptionBlock 이후의 합성곱 계층\n","        x = self.conv3(x)\n","\n","        # 그림 21에서, Global Average Pooling\n","        x = self.global_avg_pool(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":null,"id":"GF723Y_QXM9l","metadata":{"id":"GF723Y_QXM9l"},"outputs":[],"source":["if __name__ == '__main__':\n","    x = torch.randn((2, 1, 48, 48))\n","    model = Mini_Xception()\n","    y = model(x)\n","    print(y.squeeze().shape)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"vision_model_final_sol.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":5}